import uvicorn
from fastapi import FastAPI, Body, UploadFile, File, Form
from fastapi.responses import HTMLResponse, StreamingResponse, FileResponse
from fastapi.staticfiles import StaticFiles
import edge_tts
import io
import json
import os
import shutil
import subprocess
import math
import tempfile
import argparse
import asyncio
import sys
from typing import List

# ==========================================
# 1. åç«¯é€»è¾‘
# ==========================================

app = FastAPI()

# ä¸´æ—¶æ–‡ä»¶ç›®å½•
TEMP_DIR = "temp_render"
if os.path.exists(TEMP_DIR):
    shutil.rmtree(TEMP_DIR)
os.makedirs(TEMP_DIR, exist_ok=True)

# ---------------------------------------------------
# FFmpeg è¾…åŠ©å‡½æ•°
# ---------------------------------------------------

def get_duration(file_path):
    """è·å–åª’ä½“æ–‡ä»¶æ—¶é•¿(ç§’)"""
    cmd = [
        "ffprobe", "-v", "error", "-show_entries", "format=duration",
        "-of", "default=noprint_wrappers=1:nokey=1", file_path
    ]
    try:
        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        return float(result.stdout.strip())
    except:
        return 0.0

def run_ffmpeg(cmd, verbose=False, cwd=None):
    """Run FFmpeg command with optional stderr output for debugging"""
    # Force utf-8 and relax decoding to prevent crash on Windows (GBK vs UTF-8 issues)
    result = subprocess.run(cmd, capture_output=True, text=True, cwd=cwd, encoding='utf-8', errors='replace')
    if result.returncode != 0:
        if verbose:
            print(f"[FFmpeg é”™è¯¯] å‘½ä»¤: {' '.join(cmd[:5])}...")
            # Print last 800 chars of stderr
            stderr_tail = result.stderr[-800:] if len(result.stderr) > 800 else result.stderr
            print(stderr_tail)
        raise subprocess.CalledProcessError(result.returncode, cmd)
    return result

def process_render(video_path, script_data, audio_files, verbose=False, resolution="native", gpu=False):
    """
    æ ¸å¿ƒæ¸²æŸ“é€»è¾‘:
    1. éå†è„šæœ¬ï¼Œåˆ‡å‰²è§†é¢‘ï¼Œå¤„ç†éŸ³é¢‘åŒæ­¥
    2. ç”Ÿæˆç‰‡æ®µ
    3. åˆå¹¶ç‰‡æ®µ
    4. çƒ§å½•å­—å¹•
    
    Args:
        verbose: If True, print progress to terminal (CLI mode)
        resolution: 'native' ä¿æŒåŸåˆ†è¾¨ç‡, '360p' ç¼©æ”¾åˆ°640x360
        gpu: If True, use NVIDIA GPU (h264_nvenc) for encoding
    """
    # æ ¹æ® gpu å‚æ•°é€‰æ‹©ç¼–ç å™¨
    if gpu:
        video_codec = ["h264_nvenc", "-preset", "p4", "-cq", "23"]
        if verbose:
            print("[GPU] ä½¿ç”¨ NVIDIA NVENC ç¡¬ä»¶åŠ é€Ÿç¼–ç ")
    else:
        video_codec = ["libx264", "-preset", "fast", "-crf", "23"]
    output_filename = "final_output.mp4"
    final_path = os.path.join(TEMP_DIR, output_filename)
    
    segment_files = []
    srt_entries = []
    current_time_cursor = 0.0
    total_scenes = len(script_data)
    
    # Progress callback
    def update_progress(step, detail=""):
        if verbose:
            print(f"[è¿›åº¦] {step}: {detail}")
        # Also write to file for GUI mode
        with open(os.path.join(TEMP_DIR, "progress.txt"), "w", encoding="utf-8") as f:
            f.write(f"{step}|{detail}")

    segment_files = []
    srt_entries = []
    current_time_cursor = 0.0
    report_log = []

    # 1. å¤„ç†æ¯ä¸ªç‰‡æ®µ
    for idx, scene in enumerate(script_data):
        # æ”¯æŒæ–°æ ¼å¼ (fragmentsåˆ—è¡¨) å’Œæ—§æ ¼å¼ (time_start/time_end)
        fragments = scene.get('fragments', [])
        if not fragments:
            # å…¼å®¹æ—§æ ¼å¼
            start_str = scene.get('time_start', '00:00')
            end_str = scene.get('time_end', '00:05')
            fragments = [{'start': start_str, 'end': end_str, 'speed': 1.0}]
        
        def parse_time(t_str):
            t_str = str(t_str)
            p = list(map(float, t_str.split(':')))
            if len(p) == 1:  # SS (pure seconds)
                return p[0]
            elif len(p) == 2:  # MM:SS
                return p[0]*60 + p[1]
            elif len(p) == 3:  # HH:MM:SS
                return p[0]*3600 + p[1]*60 + p[2]
            else:
                raise ValueError(f"æ— æ•ˆçš„æ—¶é—´æ ¼å¼: {t_str}")
        
        # å¯¹åº”çš„éŸ³é¢‘æ–‡ä»¶
        audio_path = audio_files.get(str(idx))
        
        # ä¸´æ—¶æ–‡ä»¶å
        seg_video_name = f"seg_v_{idx}.mp4"
        seg_audio_name = f"seg_a_{idx}.wav"
        seg_out_name = f"clip_{idx}.mp4"
        
        p_seg_v = os.path.join(TEMP_DIR, seg_video_name)
        p_seg_a = os.path.join(TEMP_DIR, seg_audio_name)
        p_seg_out = os.path.join(TEMP_DIR, seg_out_name)
        
        # è·å–è§†é¢‘æ€»æ—¶é•¿
        source_video_duration = get_duration(video_path)
        
        # å¤„ç†å¤šç‰‡æ®µ: åˆ‡å‰²æ¯ä¸ªç‰‡æ®µå¹¶æ‹¼æ¥
        frag_files = []
        total_video_dur = 0
        
        for frag_idx, frag in enumerate(fragments):
            frag_start = parse_time(frag.get('start', '00:00'))
            frag_end = parse_time(frag.get('end', '00:05'))
            frag_speed = float(frag.get('speed', 1.0))
            
            # è¾¹ç•Œæ£€æŸ¥
            if frag_start >= source_video_duration:
                frag_start = max(0, source_video_duration - 2)
            if frag_end > source_video_duration:
                frag_end = source_video_duration
            
            frag_dur = frag_end - frag_start
            if frag_dur <= 0:
                frag_dur = 1
            
            # è®¡ç®—å˜é€Ÿåçš„æ—¶é•¿
            actual_frag_dur = frag_dur / frag_speed
            total_video_dur += actual_frag_dur
            
            # åˆ‡å‰²å•ä¸ªç‰‡æ®µ
            frag_file = os.path.join(TEMP_DIR, f"frag_{idx}_{frag_idx}.mp4")
            
            # æ„å»ºå˜é€Ÿæ»¤é•œ
            # æ”¯æŒè‡ªå®šä¹‰åˆ†è¾¨ç‡ï¼š360p, 480p, 720p, 1080p æˆ– nativeï¼ˆåŸå§‹ï¼‰
            scale_filter = ""
            if resolution and resolution != "native":
                res_map = {
                    "360p": "scale=640:360",
                    "480p": "scale=854:480",
                    "720p": "scale=1280:720",
                    "1080p": "scale=1920:1080",
                }
                if resolution in res_map:
                    scale_filter = res_map[resolution] + ","
                elif "x" in resolution:
                    # æ”¯æŒè‡ªå®šä¹‰ WxH æ ¼å¼ï¼Œå¦‚ "800x600"
                    scale_filter = f"scale={resolution.replace('x', ':')},"
            
            if frag_speed != 1.0:
                # setptsè°ƒæ•´è§†é¢‘é€Ÿåº¦ï¼Œä¾‹å¦‚ setpts=0.5*PTS åŠ é€Ÿ2å€
                speed_filter = f"setpts={1/frag_speed}*PTS"
                vf = f"{scale_filter}{speed_filter}"
            else:
                vf = scale_filter.rstrip(',') if scale_filter else None
            
            cmd_frag = [
                "ffmpeg", "-y", "-ss", str(frag_start), "-t", str(frag_dur),
                "-i", video_path
            ]
            if vf:
                cmd_frag.extend(["-vf", vf])
            cmd_frag.extend(["-c:v"] + video_codec + ["-an",
                frag_file
            ])
            
            try:
                run_ffmpeg(cmd_frag, verbose=verbose)
                frag_files.append(frag_file)
            except Exception as e:
                if verbose:
                    print(f"[è­¦å‘Š] ç‰‡æ®µ {idx+1} å­ç‰‡æ®µ {frag_idx+1} åˆ‡å‰²å¤±è´¥: {e}")
        
        if not frag_files:
            if verbose:
                print(f"[è·³è¿‡] ç‰‡æ®µ {idx+1}: æ— æœ‰æ•ˆå­ç‰‡æ®µ")
            continue
        
        # å¦‚æœåªæœ‰ä¸€ä¸ªç‰‡æ®µï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™æ‹¼æ¥
        if len(frag_files) == 1:
            import shutil
            shutil.copy(frag_files[0], p_seg_v)
        else:
            # ä½¿ç”¨ concat demuxer æ‹¼æ¥å¤šä¸ªç‰‡æ®µ
            concat_list = os.path.join(TEMP_DIR, f"concat_{idx}.txt")
            with open(concat_list, 'w', encoding='utf-8') as f:
                for ff in frag_files:
                    f.write(f"file '{os.path.abspath(ff)}'\n")
            
            cmd_concat = [
                "ffmpeg", "-y", "-f", "concat", "-safe", "0",
                "-i", concat_list,
            ] + ["-c:v"] + video_codec + ["-an",
                p_seg_v
            ]
            run_ffmpeg(cmd_concat, verbose=verbose)
        
        # è·å–æ‹¼æ¥åçš„å®é™…è§†é¢‘æ—¶é•¿
        actual_video_dur = get_duration(p_seg_v)
        video_dur = actual_video_dur
        
        # A. å¤„ç†éŸ³é¢‘ (è®¡ç®—æ˜¯å¦éœ€è¦å»¶é•¿è§†é¢‘)
        # å…ˆè½¬ä¸ºwavå¹¶è·å–æ—¶é•¿
        run_ffmpeg(["ffmpeg", "-y", "-i", audio_path, p_seg_a], verbose=verbose)
        audio_dur = get_duration(p_seg_a)
        
        final_audio_filter = "anull" # é»˜è®¤ä¸å¤„ç†
        
        # å¦‚æœéŸ³é¢‘æ¯”è§†é¢‘é•¿ï¼Œè‡ªåŠ¨å»¶é•¿æœ€åä¸€ä¸ªç‰‡æ®µ
        if audio_dur > video_dur + 0.1:
            diff = audio_dur - video_dur
            vo_text = scene.get('voiceover', '').strip()
            vo_snippet = (vo_text[:30] + '..') if len(vo_text) > 30 else vo_text
            
            # è·å–æœ€åä¸€ä¸ªç‰‡æ®µçš„ç»“æŸæ—¶é—´ï¼Œä»é‚£é‡Œç»§ç»­å»¶é•¿
            last_frag = fragments[-1]
            last_frag_end = parse_time(last_frag.get('end', '00:05'))
            
            # è®¡ç®—éœ€è¦å»¶é•¿å¤šå°‘
            extend_start = last_frag_end
            extend_dur = diff + 0.5  # å¤šåŠ 0.5ç§’ç¡®ä¿è¶³å¤Ÿ
            
            # æ£€æŸ¥æ˜¯å¦è¶…å‡ºæºè§†é¢‘
            if extend_start + extend_dur > source_video_duration:
                # å¦‚æœä¼šè¶…å‡ºï¼Œåªèƒ½å»¶é•¿åˆ°è§†é¢‘æœ«å°¾
                extend_dur = source_video_duration - extend_start
                if extend_dur <= 0:
                    # æºè§†é¢‘å·²ç»ç”¨å®Œäº†ï¼Œä»å¤´å¼€å§‹å¾ªç¯
                    extend_start = 0
                    extend_dur = diff + 0.5
                    if extend_dur > source_video_duration:
                        extend_dur = source_video_duration
            
            if extend_dur > 0:
                print(f"[è‡ªåŠ¨å»¶é•¿] ç‰‡æ®µ {idx+1}: ä» {extend_start:.1f}s å»¶é•¿ {extend_dur:.1f}s")
                
                # åˆ‡å‰²å»¶é•¿éƒ¨åˆ†
                extend_file = os.path.join(TEMP_DIR, f"extend_{idx}.mp4")
                
                # ä½¿ç”¨ä¸ä¸»ç‰‡æ®µç›¸åŒçš„åˆ†è¾¨ç‡é€»è¾‘
                scale_filter = None
                if resolution and resolution != "native":
                    res_map = {
                        "360p": "scale=640:360",
                        "480p": "scale=854:480",
                        "720p": "scale=1280:720",
                        "1080p": "scale=1920:1080",
                    }
                    if resolution in res_map:
                        scale_filter = res_map[resolution]
                    elif "x" in resolution:
                        scale_filter = f"scale={resolution.replace('x', ':')}"
                
                cmd_extend = [
                    "ffmpeg", "-y", "-ss", str(extend_start), "-t", str(extend_dur),
                    "-i", video_path
                ]
                if scale_filter:
                    cmd_extend.extend(["-vf", scale_filter])
                cmd_extend.extend(["-c:v"] + video_codec + ["-an",
                    extend_file
                ])
                
                try:
                    run_ffmpeg(cmd_extend, verbose=verbose)
                    
                    # æŠŠå»¶é•¿éƒ¨åˆ†æ‹¼æ¥åˆ°åŸè§†é¢‘åé¢
                    concat_extend = os.path.join(TEMP_DIR, f"concat_ext_{idx}.txt")
                    with open(concat_extend, 'w', encoding='utf-8') as f:
                        f.write(f"file '{os.path.abspath(p_seg_v)}'\n")
                        f.write(f"file '{os.path.abspath(extend_file)}'\n")
                    
                    p_seg_v_extended = os.path.join(TEMP_DIR, f"seg_v_{idx}_ext.mp4")
                    cmd_concat_ext = [
                        "ffmpeg", "-y", "-f", "concat", "-safe", "0",
                        "-i", concat_extend,
                    ] + ["-c:v"] + video_codec + ["-an",
                        p_seg_v_extended
                    ]
                    run_ffmpeg(cmd_concat_ext, verbose=verbose)
                    
                    # ç”¨å»¶é•¿åçš„è§†é¢‘æ›¿æ¢åŸæ¥çš„
                    import shutil
                    shutil.move(p_seg_v_extended, p_seg_v)
                    
                    # æ›´æ–°è§†é¢‘æ—¶é•¿
                    video_dur = get_duration(p_seg_v)
                    
                except Exception as e:
                    print(f"[è­¦å‘Š] è‡ªåŠ¨å»¶é•¿å¤±è´¥: {e}")
            
            msg = f"ç‰‡æ®µ {idx+1} [å†…å®¹: {vo_snippet}]: å·²è‡ªåŠ¨å»¶é•¿è§†é¢‘ {diff:.2f}s"
            report_log.append(msg)
        

        # C. åˆå¹¶å½“å‰ç‰‡æ®µ (è§†é¢‘ + éŸ³é¢‘)
        # æ³¨æ„ï¼šè§†é¢‘é•¿åº¦å’ŒéŸ³é¢‘é•¿åº¦å¯èƒ½ä¸å®Œå…¨ä¸€è‡´ï¼ˆç”±äºå¸§ç‡å¯¹é½ç­‰ï¼‰ï¼Œ
        # å¦‚æœè§†é¢‘å»¶é•¿åæ¯”éŸ³é¢‘ç•¥é•¿ï¼Œæˆ–è€…ç•¥çŸ­ã€‚
        # ä½¿ç”¨ -shortest å¯èƒ½ä¼šæˆªæ–­éŸ³é¢‘ã€‚å¦‚æœè§†é¢‘å®šæ ¼éœ€æ±‚ï¼Œéœ€è¦ padã€‚
        # ä¸ºç®€å•èµ·è§ï¼Œä¸”æ»¡è¶³â€œå»¶ä¼¸è§†é¢‘â€çš„éœ€æ±‚ï¼Œæˆ‘ä»¬å‡è®¾è§†é¢‘å·²ç»è¶³å¤Ÿé•¿ï¼ˆæˆ–è€…å·²åˆ°æœ«å°¾ï¼‰ã€‚
        # å¦‚æœè§†é¢‘æ¯”éŸ³é¢‘é•¿ï¼Œshortestä¼šè®©è§†é¢‘é€‚åº”éŸ³é¢‘ã€‚
        # å¦‚æœéŸ³é¢‘æ¯”è§†é¢‘é•¿(ç´ æè€—å°½)ï¼Œshortestä¼šè®©éŸ³é¢‘è¢«æˆªæ–­ã€‚è¿™æ˜¯åˆç†çš„ã€‚
        
        # æ­¤æ—¶ final_audio_filter åº”è¯¥æ˜¯ç©ºçš„æˆ–è€… anull
        
        cmd_merge = [
            "ffmpeg", "-y",
            "-i", p_seg_v,
            "-i", p_seg_a,
            "-filter_complex", f"[1:a]apad=whole_dur={video_dur}[aout]",
            "-map", "0:v", "-map", "[aout]",
            "-c:v", "copy", "-c:a", "aac",
            "-t", str(video_dur),
            p_seg_out
        ]
        run_ffmpeg(cmd_merge, verbose=verbose)
        segment_files.append(p_seg_out)
        
        # æ›´æ–°è§†é¢‘æ—¶é•¿ç”¨äºå­—å¹•è®¡æ—¶
        video_dur = get_duration(p_seg_out)
        
        # D. è®°å½•å­—å¹• (SRTæ ¼å¼)
        # æ ¼å¼: 
        # 1
        # 00:00:00,000 --> 00:00:05,000
        # å­—å¹•å†…å®¹
        def fmt_srt_time(seconds):
            m, s = divmod(seconds, 60)
            h, m = divmod(m, 60)
            ms = int((s - int(s)) * 1000)
            return f"{int(h):02d}:{int(m):02d}:{int(s):02d},{ms:03d}"
            
        srt_start = fmt_srt_time(current_time_cursor)
        srt_end = fmt_srt_time(current_time_cursor + video_dur)
        srt_entries.append(f"{idx+1}\n{srt_start} --> {srt_end}\n{scene['voiceover']}\n")
        
        current_time_cursor += video_dur

    # 2. åˆå¹¶æ‰€æœ‰ç‰‡æ®µ
    list_path = os.path.join(TEMP_DIR, "filelist.txt")
    with open(list_path, "w", encoding="utf-8") as f:
        for seg in segment_files:
            # ffmpeg concat demuxer éœ€è¦ç»å¯¹è·¯å¾„æˆ–ç›¸å¯¹è·¯å¾„ï¼Œæ³¨æ„è½¬ä¹‰
            f.write(f"file '{os.path.basename(seg)}'\n")
            
    merged_tmp = os.path.join(TEMP_DIR, "merged_tmp.mp4")
    # Use relative filename since we run with cwd=TEMP_DIR
    cmd_concat = [
        "ffmpeg", "-y", "-f", "concat", "-safe", "0",
        "-i", "filelist.txt",
        "-c:v"] + video_codec + ["-c:a", "aac", "-b:a", "128k",
        "merged_tmp.mp4"
    ]
    # æ³¨æ„ï¼šcwdè®¾ä¸ºTEMP_DIRä»¥ä¾¿è¯»å– filelist
    update_progress("åˆå¹¶ç‰‡æ®µ", "æ­£åœ¨æ‹¼æ¥æ‰€æœ‰ç‰‡æ®µ...")
    run_ffmpeg(cmd_concat, verbose=verbose, cwd=TEMP_DIR)
    
    # 3. ç”Ÿæˆ SRT æ–‡ä»¶ (ä¿å­˜å¤‡ç”¨ï¼Œä½†ä¸çƒ§å½•)
    srt_path = os.path.join(TEMP_DIR, "subs.srt")
    with open(srt_path, "w", encoding="utf-8") as f:
        f.write("\n".join(srt_entries))
        
    # 4. è·³è¿‡å­—å¹•çƒ§å½•ï¼Œç›´æ¥ä½¿ç”¨åˆå¹¶åçš„è§†é¢‘ä½œä¸ºæœ€ç»ˆè¾“å‡º
    import shutil
    shutil.copy(merged_tmp, final_path)
    update_progress("å®Œæˆ", "æ¸²æŸ“å®Œæˆï¼")
    
    # 5. ç”ŸæˆæŠ¥å‘Š
    if report_log:
        report_path = "report.txt"
        with open(report_path, "w", encoding="utf-8") as f:
            f.write("\n".join(report_log))
        if verbose:
            print(f"[æç¤º] å·²ç”Ÿæˆå»¶é•¿æŠ¥å‘Š: {report_path}")
            
    return final_path

# ---------------------------------------------------
# API
# ---------------------------------------------------

HTML_CONTENT = """
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æ™ºèƒ½è„šæœ¬é…éŸ³å‰ªè¾‘å™¨ v4.0 (å«è§†é¢‘å¯¼å‡º)</title>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400;700;900&display=swap" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/mp4-muxer@5.1.3/build/mp4-muxer.min.js"></script>
    <style>
        :root { --bg: #111827; --card: #1f2937; --text: #f3f4f6; --accent: #3b82f6; --success: #10b981; --warn: #f59e0b; --danger: #ef4444; }
        body { background-color: var(--bg); color: var(--text); font-family: "Noto Sans SC", sans-serif; margin: 0; padding: 20px; display: flex; flex-direction: column; height: 100vh; box-sizing: border-box; }
        
        /* ç½®é¡¶æ¸²æŸ“è¿›åº¦æ¡ */
        .render-progress-overlay {
            position: fixed; top: 0; left: 0; right: 0; z-index: 9999;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 12px 20px; display: none; flex-direction: column; gap: 8px;
            box-shadow: 0 4px 20px rgba(0,0,0,0.5);
        }
        .render-progress-bar { height: 8px; background: rgba(255,255,255,0.3); border-radius: 4px; overflow: hidden; }
        .render-progress-fill { height: 100%; background: #fff; width: 0%; transition: width 0.3s; border-radius: 4px; }
        .render-progress-text { font-size: 14px; font-weight: 700; color: #fff; display: flex; justify-content: space-between; }
        .render-progress-text span { opacity: 0.9; }
        
        .header { display: flex; justify-content: space-between; align-items: center; margin-bottom: 15px; }
        .header h1 { margin: 0; font-size: 20px; color: var(--accent); font-weight: 900; }

        .container { width: 100%; display: grid; grid-template-columns: 1fr 360px; gap: 20px; flex: 1; min-height: 0; }
        
        .video-wrapper { display: flex; flex-direction: column; height: 100%; gap: 10px; }
        .video-section { flex: 1; background: #000; border-radius: 12px; overflow: hidden; position: relative; display: flex; align-items: center; justify-content: center; }
        video { width: 100%; height: 100%; max-height: 100%; display: block; }
        
        .subtitle-overlay { position: absolute; bottom: 8%; width: 100%; text-align: center; pointer-events: none; z-index: 5; }
        .subtitle-text { 
            font-family: 'Noto Sans SC', sans-serif; font-weight: 900; 
            color: #fff; font-size: 32px; line-height: 1.3;
            text-shadow: 2px 2px 0px rgba(0,0,0,0.8);
            background: rgba(0,0,0,0.4); backdrop-filter: blur(2px);
            padding: 8px 16px; border-radius: 6px; 
            display: inline-block; max-width: 90%; opacity: 0;
        }
        
        .loading-overlay { position: absolute; inset: 0; background: rgba(0,0,0,0.8); display: flex; flex-direction: column; align-items: center; justify-content: center; z-index: 20; display: none; }
        .spinner { width: 40px; height: 40px; border: 4px solid #fff; border-top-color: var(--accent); border-radius: 50%; animation: spin 1s linear infinite; margin-bottom: 15px; }
        .progress-text { font-size: 14px; color: #fff; margin-top: 10px; }

        .player-controls { background: var(--card); padding: 10px; border-radius: 8px; display: flex; align-items: center; justify-content: center; gap: 10px; }
        .ctrl-btn { background: #374151; border: none; color: white; padding: 8px 16px; border-radius: 6px; cursor: pointer; font-size: 14px; font-weight: 700; font-family: "Noto Sans SC"; }
        .ctrl-btn:hover { background: #4b5563; }
        .ctrl-btn.main { background: var(--accent); font-weight: 900; }
        .ctrl-btn.reset { background: var(--warn); color: #000; }
        .ctrl-btn.render { background: #8b5cf6; color: #fff; }
        .ctrl-btn.render:hover { background: #7c3aed; }
        
        /* è¿›åº¦æ¡æ ·å¼ */
        .progress-bar-container { background: var(--card); padding: 8px 15px; border-radius: 8px; display: flex; align-items: center; gap: 10px; }
        .time-display { font-size: 12px; color: #9ca3af; min-width: 80px; font-family: monospace; }
        .progress-slider { flex: 1; height: 6px; -webkit-appearance: none; appearance: none; background: #374151; border-radius: 3px; cursor: pointer; }
        .progress-slider::-webkit-slider-thumb { -webkit-appearance: none; width: 14px; height: 14px; background: var(--accent); border-radius: 50%; cursor: grab; }
        .progress-slider::-moz-range-thumb { width: 14px; height: 14px; background: var(--accent); border-radius: 50%; cursor: grab; border: none; }
        .progress-slider::-webkit-slider-runnable-track { height: 6px; background: linear-gradient(to right, var(--accent) var(--progress, 0%), #374151 var(--progress, 0%)); border-radius: 3px; }
        .progress-slider:active::-webkit-slider-thumb { cursor: grabbing; }

        .sidebar { background: var(--card); padding: 20px; border-radius: 12px; display: flex; flex-direction: column; gap: 15px; overflow-y: auto; }
        h2 { margin: 0 0 8px 0; font-size: 14px; color: #9ca3af; font-weight: 700; border-bottom: 1px solid #374151; padding-bottom: 5px; }
        input, select, textarea { width: 100%; background: #374151; border: 1px solid #4b5563; color: white; padding: 8px; border-radius: 4px; box-sizing: border-box; font-family: inherit; }
        textarea { height: 120px; font-family: monospace; font-size: 12px; }

        .status-list { flex: 1; overflow-y: auto; background: #111; border-radius: 6px; padding: 10px; font-size: 12px; border: 1px solid #333; }
        .status-item { padding: 4px 0; border-bottom: 1px solid #222; display: flex; justify-content: space-between; }
        .status-ready { color: var(--success); }

        @keyframes spin { to { transform: rotate(360deg); } }
    </style>
</head>
<body>

<!-- ç½®é¡¶æ¸²æŸ“è¿›åº¦æ¡ -->
<div id="renderProgressOverlay" class="render-progress-overlay">
    <div class="render-progress-text">
        <span id="renderProgressLabel">ğŸ¬ æ¸²æŸ“ä¸­...</span>
        <span id="renderProgressPercent">0%</span>
    </div>
    <div class="render-progress-bar">
        <div id="renderProgressFill" class="render-progress-fill"></div>
    </div>
    <div class="render-progress-text">
        <span id="renderProgressDetail">å‡†å¤‡ä¸­...</span>
        <span id="renderProgressETA">é¢„è®¡å‰©ä½™: --</span>
    </div>
</div>

<div class="header">
    <h1>ğŸ¬ æ™ºèƒ½é…éŸ³å‰ªè¾‘å™¨ <span style="font-size:12px; opacity:0.6;">v5.0 WebCodecs</span></h1>
    <div style="font-size: 12px; color: #aaa;">æ”¯æŒæµè§ˆå™¨æœ¬åœ°æ¸²æŸ“ / FFmpeg åç«¯æ¸²æŸ“</div>
</div>

<div class="container">
    <div class="video-wrapper">
        <div class="video-section">
            <video id="mainVideo" playsinline onclick="togglePlayPause()"></video>
            <div class="subtitle-overlay"><div id="subtitle" class="subtitle-text"></div></div>
            
            <!-- åŠ è½½é®ç½© -->
            <div id="loader" class="loading-overlay">
                <div class="spinner"></div>
                <div id="loaderTitle" style="font-size:16px; font-weight:bold;">å¤„ç†ä¸­...</div>
                <div id="loaderMsg" class="progress-text">0%</div>
            </div>
        </div>
        
        <!-- è¿›åº¦æ¡ -->
        <div class="progress-bar-container">
            <span class="time-display" id="currentTime">00:00 / 00:00</span>
            <input type="range" class="progress-slider" id="progressSlider" min="0" max="100" value="0" step="0.1">
        </div>
        
        <div class="player-controls">
            <button class="ctrl-btn reset" onclick="resetProject()">â†º é‡ç½®</button>
            <div style="width:1px; height:20px; background:#555; margin:0 5px;"></div>
            <button class="ctrl-btn" onclick="seek(-10)">âª</button>
            <button class="ctrl-btn main" id="playPauseBtn" onclick="togglePlayPause()">â–¶ å¼€å§‹é¢„è§ˆ</button>
            <button class="ctrl-btn" onclick="seek(10)">â©</button>
            <div style="width:1px; height:20px; background:#555; margin:0 5px;"></div>
            <select id="renderMode" style="background:#374151; border:1px solid #4b5563; color:#fff; padding:6px 10px; border-radius:6px; font-size:12px;">
                <option value="webcodecs" selected>ğŸŒ æµè§ˆå™¨æ¸²æŸ“</option>
                <option value="ffmpeg">ğŸ–¥ï¸ FFmpegæ¸²æŸ“</option>
                <option value="cli">ğŸ’» CLIæ¸²æŸ“</option>
            </select>
            <select id="renderResolution" style="background:#374151; border:1px solid #4b5563; color:#fff; padding:6px 10px; border-radius:6px; font-size:12px;">
                <option value="native">åŸç”Ÿåˆ†è¾¨ç‡</option>
                <option value="360p">360på¿«é€Ÿ</option>
            </select>
            <button class="ctrl-btn render" onclick="startRender()">ğŸ¥ æ¸²æŸ“å¯¼å‡º</button>
            <button class="ctrl-btn" style="background:#10b981;" onclick="exportProject()">ğŸ“ å¯¼å‡ºå·¥ç¨‹</button>
        </div>
    </div>

    <div class="sidebar">
        <div>
            <h2>1. è§†é¢‘æº</h2>
            <input type="file" id="videoInput" accept="video/*">
        </div>
        
        <div>
            <h2>2. è„šæœ¬ (JSON)</h2>
            <textarea id="scriptInput"></textarea>
        </div>

        <div>
            <h2>3. è¯­éŸ³é…ç½®</h2>
            <div style="display:grid; grid-template-columns: 1fr 1fr; gap:10px; margin-bottom:10px;">
                <select id="voiceSelect">
                    <option value="zh-CN-XiaoxiaoNeural">æ™“æ™“ (å¥³å£°)</option>
                    <option value="zh-CN-YunxiNeural">äº‘å¸Œ (ç”·å£°)</option>
                </select>
                <select id="rateSelect">
                    <option value="+0%">åŸé€Ÿ</option>
                    <option value="+25%">1.25x</option>
                    <option value="+50%">1.5x</option>
                </select>
            </div>
            <select id="fontWeightSelect" onchange="updateSubtitleStyle()">
                <option value="900" selected>å­—å¹•: ç²—é»‘ (900)</option>
                <option value="700">å­—å¹•: ç²—ä½“ (700)</option>
            </select>
        </div>

        <div style="display:flex; flex-direction:column; flex:1;">
            <h2>ç”Ÿæˆé˜Ÿåˆ—</h2>
            <div class="status-list" id="statusList"></div>
        </div>
    </div>
</div>

<script>
    // --- çŠ¶æ€ ---
    const PREFETCH_LIMIT = 3;
    let scriptData = [];
    let audioCache = new Map(); // index -> { blob, url, text }
    let isGenerating = false;
    let isRunning = false;      
    let isPaused = false;       
    let abortController = null;
    let currentSceneIndex = 0;
    let currentAudioObj = null; 
    let selectedVideoFile = null;

    // --- IndexedDB éŸ³é¢‘ç¼“å­˜ ---
    const DB_NAME = 'TTSAudioCache';
    const DB_VERSION = 1;
    const STORE_NAME = 'audios';
    let dbInstance = null;

    async function openDB() {
        if (dbInstance) return dbInstance;
        return new Promise((resolve, reject) => {
            const request = indexedDB.open(DB_NAME, DB_VERSION);
            request.onerror = () => reject(request.error);
            request.onsuccess = () => { dbInstance = request.result; resolve(dbInstance); };
            request.onupgradeneeded = (e) => {
                const db = e.target.result;
                if (!db.objectStoreNames.contains(STORE_NAME)) {
                    db.createObjectStore(STORE_NAME, { keyPath: 'key' });
                }
            };
        });
    }

    function getCacheKey(text, voice, rate) {
        return `${voice}|${rate}|${text.substring(0, 100)}`;
    }

    async function getCachedAudio(key) {
        try {
            const db = await openDB();
            return new Promise((resolve) => {
                const tx = db.transaction(STORE_NAME, 'readonly');
                const store = tx.objectStore(STORE_NAME);
                const request = store.get(key);
                request.onsuccess = () => resolve(request.result?.blob || null);
                request.onerror = () => resolve(null);
            });
        } catch { return null; }
    }

    async function setCachedAudio(key, blob) {
        try {
            const db = await openDB();
            return new Promise((resolve) => {
                const tx = db.transaction(STORE_NAME, 'readwrite');
                const store = tx.objectStore(STORE_NAME);
                store.put({ key, blob, timestamp: Date.now() });
                tx.oncomplete = () => resolve(true);
                tx.onerror = () => resolve(false);
            });
        } catch { return false; }
    }

    // --- DOM ---
    const video = document.getElementById('mainVideo');
    const subtitleEl = document.getElementById('subtitle');
    const statusList = document.getElementById('statusList');
    const loader = document.getElementById('loader');
    const loaderTitle = document.getElementById('loaderTitle');
    const loaderMsg = document.getElementById('loaderMsg');
    const playPauseBtn = document.getElementById('playPauseBtn');
    const progressSlider = document.getElementById('progressSlider');
    const currentTimeDisplay = document.getElementById('currentTime');
    
    // --- è¿›åº¦æ¡æ§åˆ¶ (åŸºäºè„šæœ¬æ—¶é•¿) ---
    let isSeeking = false;
    let scriptTotalDuration = 0;  // è„šæœ¬æ€»æ—¶é•¿
    let scriptCurrentTime = 0;    // å½“å‰æ’­æ”¾ä½ç½®
    let segmentStartTimes = [];   // æ¯ä¸ªç‰‡æ®µçš„å¼€å§‹æ—¶é—´ç‚¹
    
    function formatTime(seconds) {
        const m = Math.floor(seconds / 60);
        const s = Math.floor(seconds % 60);
        return `${m.toString().padStart(2, '0')}:${s.toString().padStart(2, '0')}`;
    }
    
    function calculateScriptDuration() {
        scriptTotalDuration = 0;
        segmentStartTimes = [];
        for (let i = 0; i < scriptData.length; i++) {
            segmentStartTimes.push(scriptTotalDuration);
            const scene = scriptData[i];
            const start = parseTime(scene.time_start);
            const end = parseTime(scene.time_end);
            scriptTotalDuration += (end - start);
        }
        updateProgressDisplay();
    }
    
    function updateProgressDisplay() {
        if (scriptTotalDuration <= 0 || isSeeking) return;
        const progress = (scriptCurrentTime / scriptTotalDuration) * 100;
        progressSlider.value = progress;
        progressSlider.style.setProperty('--progress', progress + '%');
        currentTimeDisplay.textContent = `${formatTime(scriptCurrentTime)} / ${formatTime(scriptTotalDuration)}`;
    }
    
    function updateProgressBar() {
        // è¿™ä¸ªå‡½æ•°ä¸å†ä½¿ç”¨videoæ—¶é—´ï¼Œæ”¹ç”¨è„šæœ¬æ—¶é—´è®¡ç®—
        updateProgressDisplay();
    }
    
    // æ ¹æ®è„šæœ¬æ—¶é—´æ‰¾åˆ°å¯¹åº”çš„ç‰‡æ®µå’Œç‰‡æ®µå†…ä½ç½®
    function findSegmentByScriptTime(time) {
        for (let i = scriptData.length - 1; i >= 0; i--) {
            if (time >= segmentStartTimes[i]) {
                const scene = scriptData[i];
                const segDuration = parseTime(scene.time_end) - parseTime(scene.time_start);
                const timeInSegment = Math.min(time - segmentStartTimes[i], segDuration);
                return { index: i, timeInSegment, videoTime: parseTime(scene.time_start) + timeInSegment };
            }
        }
        return { index: 0, timeInSegment: 0, videoTime: parseTime(scriptData[0]?.time_start || '0:0') };
    }
    
    let wasPlaying = false;
    
    progressSlider.addEventListener('mousedown', () => {
        wasPlaying = isRunning && !isPaused;
        if (wasPlaying) {
            isPaused = true;
            video.pause();
            if (currentAudioObj) currentAudioObj.pause();
        }
    });
    
    progressSlider.addEventListener('input', (e) => {
        isSeeking = true;
        if (scriptTotalDuration <= 0 || scriptData.length === 0) return;
        const newTime = (e.target.value / 100) * scriptTotalDuration;
        scriptCurrentTime = newTime;
        currentTimeDisplay.textContent = `${formatTime(newTime)} / ${formatTime(scriptTotalDuration)}`;
        progressSlider.style.setProperty('--progress', e.target.value + '%');
        
        // è·³è½¬è§†é¢‘åˆ°å¯¹åº”ä½ç½®
        const seg = findSegmentByScriptTime(newTime);
        video.currentTime = seg.videoTime;
        
        // åŒæ­¥æ›´æ–°å­—å¹•
        if (scriptData[seg.index]) {
            subtitleEl.innerText = scriptData[seg.index].voiceover;
            subtitleEl.style.opacity = 1;
        }
        
        console.log('Seek:', newTime, '-> segment', seg.index, 'videoTime', seg.videoTime);
    });
    
    progressSlider.addEventListener('change', (e) => {
        if (scriptTotalDuration <= 0) {
            isSeeking = false;
            return;
        }
        const newTime = (e.target.value / 100) * scriptTotalDuration;
        scriptCurrentTime = newTime;
        const seg = findSegmentByScriptTime(newTime);
        
        isSeeking = false;
        
        // å¦‚æœä¹‹å‰åœ¨æ’­æ”¾ï¼Œè·³è½¬åˆ°å¯¹åº”ç‰‡æ®µç»§ç»­
        if (wasPlaying && isRunning) {
            currentSceneIndex = seg.index;
            isPaused = false;
            // ä»å½“å‰ç‰‡æ®µé‡æ–°å¼€å§‹æ’­æ”¾ï¼Œå¹¶ä¼ å…¥åç§»é‡
            playScene(seg.index, seg.timeInSegment);
        } else if (isRunning) {
            // æš‚åœçŠ¶æ€ä¸‹åªå®šä½
            currentSceneIndex = seg.index;
            playScene(seg.index, seg.timeInSegment, true); // true = ä»…å®šä½ä¸æ’­æ”¾
        }
    });

    // é»˜è®¤è„šæœ¬
    const defaultScript = {
        "script_content": [
            { "scenes": [
                { "time_start": "00:00", "time_end": "00:05", "voiceover": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ¸²æŸ“çš„è„šæœ¬ã€‚ç‚¹å‡»ç´«è‰²æŒ‰é’®å¯¼å‡ºã€‚" },
                { "time_start": "00:05", "time_end": "00:10", "voiceover": "ç³»ç»Ÿä¼šç¡®ä¿æ‰€æœ‰è¯­éŸ³å…ˆç”Ÿæˆå®Œæ¯•ï¼Œç„¶åè°ƒç”¨ FFmpeg åˆå¹¶ã€‚" },
                { "time_start": "00:10", "time_end": "00:15", "voiceover": "æœ€åæ‚¨å°†ä¸‹è½½åˆ°ä¸€ä¸ªåŒ…å«å­—å¹•ç¡¬çƒ§çš„ MP4 æ–‡ä»¶ã€‚" }
            ]}
        ]
    };
    document.getElementById('scriptInput').value = JSON.stringify(defaultScript, null, 2);

    // ========== æ™ºèƒ½è„šæœ¬è§£æå™¨ ==========
    function parseScriptSmart(inputText) {
        const result = { scenes: [], warnings: [], errors: [] };
        let raw = null;
        
        // Step 1: å°è¯•è§£æJSON
        try {
            raw = JSON.parse(inputText);
        } catch (jsonError) {
            // JSONè§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤å¸¸è§é—®é¢˜
            let fixed = inputText
                .replace(/,\s*}/g, '}')  // ç§»é™¤å°¾éšé€—å·
                .replace(/,\s*]/g, ']')  // ç§»é™¤æ•°ç»„å°¾éšé€—å·
                .replace(/'/g, '"')       // å•å¼•å·è½¬åŒå¼•å·
                .replace(/(\w+):/g, '"$1":'); // æ— å¼•å·çš„key
            
            try {
                raw = JSON.parse(fixed);
                result.warnings.push('JSONæ ¼å¼å·²è‡ªåŠ¨ä¿®å¤ï¼ˆå°¾éšé€—å·/å¼•å·é—®é¢˜ï¼‰');
            } catch (e2) {
                result.errors.push(`JSONè§£æå¤±è´¥: ${jsonError.message}`);
                // å°è¯•æå–è¡Œå·
                const match = jsonError.message.match(/position (\d+)/);
                if (match) {
                    const pos = parseInt(match[1]);
                    const lines = inputText.substring(0, pos).split('\n');
                    result.errors.push(`é”™è¯¯ä½ç½®: ç¬¬ ${lines.length} è¡Œï¼Œç¬¬ ${lines[lines.length-1].length + 1} åˆ—`);
                    result.errors.push(`é—®é¢˜é™„è¿‘: "${inputText.substring(Math.max(0, pos-20), pos+20)}"`);
                }
                return result;
            }
        }
        
        // Step 2: æ™ºèƒ½æå–scenesæ•°ç»„
        let scenesArray = [];
        
        // æ ¼å¼1: { script_content: [ { scenes: [...] } ] }
        if (raw.script_content && Array.isArray(raw.script_content)) {
            raw.script_content.forEach((part, partIdx) => {
                if (part.scenes && Array.isArray(part.scenes)) {
                    scenesArray.push(...part.scenes);
                } else if (Array.isArray(part)) {
                    scenesArray.push(...part);
                }
            });
        }
        // æ ¼å¼2: { scenes: [...] }
        else if (raw.scenes && Array.isArray(raw.scenes)) {
            scenesArray = raw.scenes;
        }
        // æ ¼å¼3: { script: [...] }
        else if (raw.script && Array.isArray(raw.script)) {
            scenesArray = raw.script;
        }
        // æ ¼å¼4: ç›´æ¥æ˜¯æ•°ç»„ [...]
        else if (Array.isArray(raw)) {
            scenesArray = raw;
        }
        // æ ¼å¼5: å•ä¸ªå¯¹è±¡ { time_start, time_end, voiceover }
        else if (raw.time_start && raw.voiceover) {
            scenesArray = [raw];
        }
        else {
            result.errors.push('æ— æ³•è¯†åˆ«è„šæœ¬æ ¼å¼ã€‚æ”¯æŒçš„æ ¼å¼ï¼š');
            result.errors.push('  1. { "script_content": [{ "scenes": [...] }] }');
            result.errors.push('  2. { "scenes": [...] }');
            result.errors.push('  3. { "script": [...] }');
            result.errors.push('  4. [ {...}, {...} ]');
            return result;
        }
        
        // Step 3: éªŒè¯å¹¶ä¿®å¤æ¯ä¸ªscene
        let lastEndTime = 0;
        scenesArray.forEach((scene, idx) => {
            const sceneNum = idx + 1;
            const issues = [];
            let fixedScene = { ...scene };
            
            // æ£€æŸ¥å¿…è¦å­—æ®µ
            const hasStart = scene.time_start !== undefined;
            const hasEnd = scene.time_end !== undefined;
            const hasVoiceover = scene.voiceover !== undefined || scene.text !== undefined || scene.content !== undefined;
            
            // ä¿®å¤voiceoverå­—æ®µå
            if (!scene.voiceover) {
                if (scene.text) { fixedScene.voiceover = scene.text; issues.push('ä½¿ç”¨ text ä½œä¸º voiceover'); }
                else if (scene.content) { fixedScene.voiceover = scene.content; issues.push('ä½¿ç”¨ content ä½œä¸º voiceover'); }
                else if (scene.subtitle) { fixedScene.voiceover = scene.subtitle; issues.push('ä½¿ç”¨ subtitle ä½œä¸º voiceover'); }
            }
            
            // ä¿®å¤æ—¶é—´å­—æ®µå
            if (!scene.time_start) {
                if (scene.start) { fixedScene.time_start = scene.start; issues.push('ä½¿ç”¨ start ä½œä¸º time_start'); }
                else if (scene.begin) { fixedScene.time_start = scene.begin; issues.push('ä½¿ç”¨ begin ä½œä¸º time_start'); }
                else if (scene.startTime) { fixedScene.time_start = scene.startTime; }
            }
            if (!scene.time_end) {
                if (scene.end) { fixedScene.time_end = scene.end; issues.push('ä½¿ç”¨ end ä½œä¸º time_end'); }
                else if (scene.endTime) { fixedScene.time_end = scene.endTime; }
            }
            
            // éªŒè¯æœ€ç»ˆç»“æœ
            if (!fixedScene.time_start) {
                // è‡ªåŠ¨ç”Ÿæˆå¼€å§‹æ—¶é—´
                fixedScene.time_start = formatTimeForScript(lastEndTime);
                issues.push(`ç¼ºå°‘ time_startï¼Œè‡ªåŠ¨è®¾ä¸º ${fixedScene.time_start}`);
            }
            if (!fixedScene.time_end) {
                // è‡ªåŠ¨ç”Ÿæˆç»“æŸæ—¶é—´ï¼ˆå¼€å§‹æ—¶é—´ + 5ç§’ï¼‰
                const startSec = parseTime(fixedScene.time_start);
                fixedScene.time_end = formatTimeForScript(startSec + 5);
                issues.push(`ç¼ºå°‘ time_endï¼Œè‡ªåŠ¨è®¾ä¸º ${fixedScene.time_end}`);
            }
            if (!fixedScene.voiceover) {
                issues.push('ç¼ºå°‘ voiceover æ–‡æœ¬ï¼Œå·²è·³è¿‡');
                result.warnings.push(`ç‰‡æ®µ ${sceneNum}: ${issues.join('; ')}`);
                return; // è·³è¿‡è¿™ä¸ªscene
            }
            
            // éªŒè¯æ—¶é—´æ ¼å¼
            try {
                const startSec = parseTime(fixedScene.time_start);
                const endSec = parseTime(fixedScene.time_end);
                if (endSec <= startSec) {
                    issues.push(`ç»“æŸæ—¶é—´ <= å¼€å§‹æ—¶é—´ï¼Œè‡ªåŠ¨ä¿®æ­£`);
                    fixedScene.time_end = formatTimeForScript(startSec + 5);
                }
                lastEndTime = parseTime(fixedScene.time_end);
            } catch (e) {
                issues.push(`æ—¶é—´æ ¼å¼é”™è¯¯: ${e.message}`);
            }
            
            // æ¸…ç†voiceoveræ–‡æœ¬
            if (typeof fixedScene.voiceover === 'string') {
                fixedScene.voiceover = fixedScene.voiceover.trim();
                if (fixedScene.voiceover.length === 0) {
                    issues.push('voiceover ä¸ºç©ºï¼Œå·²è·³è¿‡');
                    result.warnings.push(`ç‰‡æ®µ ${sceneNum}: ${issues.join('; ')}`);
                    return;
                }
            }
            
            // æ·»åŠ åˆ°ç»“æœ
            result.scenes.push(fixedScene);
            if (issues.length > 0) {
                result.warnings.push(`ç‰‡æ®µ ${sceneNum}: ${issues.join('; ')}`);
            }
        });
        
        if (result.scenes.length === 0 && scenesArray.length > 0) {
            result.errors.push(`æ‰€æœ‰ ${scenesArray.length} ä¸ªç‰‡æ®µéƒ½æ— æ³•ä½¿ç”¨`);
        }
        
        return result;
    }
    
    function formatTimeForScript(seconds) {
        const m = Math.floor(seconds / 60);
        const s = Math.floor(seconds % 60);
        return `${m.toString().padStart(2, '0')}:${s.toString().padStart(2, '0')}`;
    }
    
    // æ˜¾ç¤ºè§£æç»“æœçš„å‡½æ•°
    function showParseResult(result) {
        let msg = '';
        if (result.errors.length > 0) {
            msg += 'âŒ é”™è¯¯:\\n' + result.errors.join('\\n') + '\\n\\n';
        }
        if (result.warnings.length > 0) {
            msg += 'âš ï¸ è­¦å‘Š (å·²è‡ªåŠ¨ä¿®å¤):\\n' + result.warnings.join('\\n') + '\\n\\n';
        }
        if (result.scenes.length > 0) {
            msg += `âœ… æˆåŠŸè§£æ ${result.scenes.length} ä¸ªç‰‡æ®µ`;
        }
        return msg;
    }

    // æ–‡ä»¶é€‰æ‹©
    document.getElementById('videoInput').addEventListener('change', (e) => {
        const file = e.target.files[0];
        if (file) {
            selectedVideoFile = file;
            video.src = URL.createObjectURL(file);
            video.load();
        }
    });

    function updateSubtitleStyle() {
        subtitleEl.style.fontWeight = document.getElementById('fontWeightSelect').value;
    }

    // --- å¯¼å‡ºå·¥ç¨‹æ–‡ä»¶ ---
    function exportProject() {
        // ä½¿ç”¨æ™ºèƒ½è§£æå™¨
        const inputText = document.getElementById('scriptInput').value;
        const parseResult = parseScriptSmart(inputText);
        
        if (parseResult.errors.length > 0) {
            alert(showParseResult(parseResult));
            return;
        }
        
        let currentScript = parseResult.scenes;
        if (parseResult.warnings.length > 0) {
            console.warn("è§£æè­¦å‘Š:", parseResult.warnings);
        }
        
        if (currentScript.length === 0) {
            alert("è„šæœ¬ä¸ºç©ºï¼Œæ— æ³•å¯¼å‡º");
            return;
        }
        
        // æ„å»ºå·¥ç¨‹æ–‡ä»¶
        const project = {
            video_path: selectedVideoFile ? selectedVideoFile.name : "è¯·å¡«å…¥è§†é¢‘ç»å¯¹è·¯å¾„",
            voice: document.getElementById('voiceSelect').value,
            rate: document.getElementById('rateSelect').value,
            script: currentScript
        };
        
        // ä¸‹è½½ JSON
        const blob = new Blob([JSON.stringify(project, null, 2)], {type: 'application/json'});
        const url = URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = url;
        a.download = 'project.json';
        document.body.appendChild(a);
        a.click();
        document.body.removeChild(a);
        URL.revokeObjectURL(url);
        
        alert("å·¥ç¨‹æ–‡ä»¶å·²å¯¼å‡ºï¼\\n\\nè¯·æ³¨æ„ï¼švideo_path éœ€è¦æ‰‹åŠ¨ä¿®æ”¹ä¸ºè§†é¢‘çš„ç»å¯¹è·¯å¾„ã€‚\\n\\nä½¿ç”¨æ–¹æ³•ï¼špython app.py --render project.json");
    }
    
    // ========== æ¸²æŸ“å…¥å£ ==========
    function startRender() {
        const mode = document.getElementById('renderMode').value;
        if (mode === 'webcodecs') {
            startWebCodecsRender();
        } else if (mode === 'cli') {
            startCLIRender();
        } else {
            startRenderExport(); // FFmpeg æœåŠ¡å™¨æ¨¡å¼
        }
    }
    
    // ========== CLI æ¸²æŸ“æ¨¡å¼ ==========
    async function startCLIRender() {
        if (!selectedVideoFile) { alert("è¯·å…ˆä¸Šä¼ è§†é¢‘æ–‡ä»¶ï¼"); return; }
        
        // ä½¿ç”¨æ™ºèƒ½è§£æå™¨
        const inputText = document.getElementById('scriptInput').value;
        const parseResult = parseScriptSmart(inputText);
        
        if (parseResult.errors.length > 0) {
            alert(showParseResult(parseResult));
            return;
        }
        
        let currentScript = parseResult.scenes;
        if (parseResult.warnings.length > 0) {
            console.warn("è§£æè­¦å‘Š:", parseResult.warnings);
        }
        
        if (currentScript.length === 0) {
            alert("è„šæœ¬ä¸ºç©ºï¼Œæ— æ³•å¯¼å‡º");
            return;
        }
        
        // 2. ç”Ÿæˆæ‰€æœ‰TTSéŸ³é¢‘ï¼ˆç¡®ä¿ç¼“å­˜ï¼‰
        showRenderProgress(true, "å‡†å¤‡CLIæ¸²æŸ“...", "ç”ŸæˆTTSéŸ³é¢‘");
        try {
            for (let i = 0; i < currentScript.length; i++) {
                if (!audioCache.has(i)) {
                    updateRenderProgress((i / currentScript.length) * 50, `ç”Ÿæˆè¯­éŸ³ ${i+1}/${currentScript.length}`, "");
                    const blob = await fetchTTS(currentScript[i].voiceover);
                    audioCache.set(i, { url: URL.createObjectURL(blob), blob, text: currentScript[i].voiceover });
                }
            }
        } catch (e) {
            showRenderProgress(false);
            alert("è¯­éŸ³ç”Ÿæˆå¤±è´¥: " + e.message);
            return;
        }
        
        // 3. æ„å»ºå·¥ç¨‹æ–‡ä»¶
        const resolution = document.getElementById('renderResolution').value;
        const project = {
            video_path: "è¯·å¡«å…¥è§†é¢‘ç»å¯¹è·¯å¾„",
            voice: document.getElementById('voiceSelect').value,
            rate: document.getElementById('rateSelect').value,
            resolution: resolution,  // 'native' æˆ– '360p'
            script: currentScript
        };
        
        // 4. ä¸‹è½½å·¥ç¨‹æ–‡ä»¶
        updateRenderProgress(60, "å¯¼å‡ºå·¥ç¨‹æ–‡ä»¶...", "");
        const projectBlob = new Blob([JSON.stringify(project, null, 2)], {type: 'application/json'});
        const projectUrl = URL.createObjectURL(projectBlob);
        const a1 = document.createElement('a');
        a1.href = projectUrl;
        a1.download = 'project.json';
        document.body.appendChild(a1);
        a1.click();
        document.body.removeChild(a1);
        URL.revokeObjectURL(projectUrl);
        
        // 5. ä¸‹è½½æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶ä¸ºZIPï¼ˆç®€åŒ–ï¼šé€ä¸ªä¸‹è½½ï¼‰
        updateRenderProgress(70, "å¯¼å‡ºéŸ³é¢‘æ–‡ä»¶...", "");
        for (let i = 0; i < currentScript.length; i++) {
            const cached = audioCache.get(i);
            if (cached) {
                const audioUrl = URL.createObjectURL(cached.blob);
                const a2 = document.createElement('a');
                a2.href = audioUrl;
                a2.download = `audio_${i}.mp3`;
                document.body.appendChild(a2);
                a2.click();
                document.body.removeChild(a2);
                URL.revokeObjectURL(audioUrl);
                await new Promise(r => setTimeout(r, 200)); // é¿å…æµè§ˆå™¨é˜»æ­¢å¤šæ¬¡ä¸‹è½½
            }
        }
        
        // 6. æ˜¾ç¤ºCLIå‘½ä»¤
        updateRenderProgress(100, "å®Œæˆï¼", "");
        const cliCommand = `python app.py --render project.json`;
        
        // å¤åˆ¶åˆ°å‰ªè´´æ¿
        try {
            await navigator.clipboard.writeText(cliCommand);
        } catch {}
        
        showRenderProgress(false);
        alert(`CLIæ¸²æŸ“æ–‡ä»¶å·²å¯¼å‡ºï¼\\n\\næ­¥éª¤ï¼š\\n1. å°†ä¸‹è½½çš„ project.json ä¸­ video_path æ”¹ä¸ºè§†é¢‘ç»å¯¹è·¯å¾„\\n2. ç¡®ä¿éŸ³é¢‘æ–‡ä»¶ audio_*.mp3 åœ¨åŒä¸€ç›®å½•\\n3. è¿è¡Œå‘½ä»¤ï¼š\\n\\n${cliCommand}\\n\\n(å‘½ä»¤å·²å¤åˆ¶åˆ°å‰ªè´´æ¿)`);
    }
    
    // ========== WebCodecs æµè§ˆå™¨æ¸²æŸ“å™¨ (ä¼˜åŒ–ç‰ˆ) ==========
    async function startWebCodecsRender() {
        if (!selectedVideoFile) { alert("è¯·å…ˆä¸Šä¼ è§†é¢‘æ–‡ä»¶ï¼"); return; }
        
        // æ£€æŸ¥ WebCodecs æ”¯æŒ
        if (!('VideoEncoder' in window) || !('AudioEncoder' in window)) {
            alert("æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒ WebCodecs APIï¼\\nè¯·ä½¿ç”¨æœ€æ–°ç‰ˆ Chrome/Edgeï¼Œæˆ–åˆ‡æ¢åˆ° FFmpeg æ¨¡å¼ã€‚");
            return;
        }
        
        // ä½¿ç”¨æ™ºèƒ½è§£æå™¨
        const inputText = document.getElementById('scriptInput').value;
        const parseResult = parseScriptSmart(inputText);
        
        if (parseResult.errors.length > 0) {
            alert(showParseResult(parseResult));
            return;
        }
        
        scriptData = parseResult.scenes;
        if (parseResult.warnings.length > 0) {
            console.warn("è§£æè­¦å‘Š:", parseResult.warnings);
        }
        
        if (scriptData.length === 0) { alert("è„šæœ¬ä¸ºç©º"); return; }
        
        // 2. ç”Ÿæˆæ‰€æœ‰éŸ³é¢‘å¹¶è§£ç 
        showRenderProgress(true, "å‡†å¤‡ä¸­...", "è§£ç éŸ³é¢‘æ•°æ®");
        const audioBuffers = [];
        const audioContext = new AudioContext();
        
        try {
            for (let i = 0; i < scriptData.length; i++) {
                if (!audioCache.has(i)) {
                    updateRenderProgress((i / scriptData.length) * 10, `ç”Ÿæˆè¯­éŸ³ ${i+1}/${scriptData.length}`, "");
                    const blob = await fetchTTS(scriptData[i].voiceover);
                    audioCache.set(i, { url: URL.createObjectURL(blob), blob, text: scriptData[i].voiceover });
                }
                // è§£ç éŸ³é¢‘æ•°æ®ç”¨äºæ··åˆ
                const cached = audioCache.get(i);
                const arrayBuffer = await cached.blob.arrayBuffer();
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                audioBuffers.push(audioBuffer);
            }
        } catch (e) {
            showRenderProgress(false);
            alert("éŸ³é¢‘å¤„ç†å¤±è´¥: " + e.message);
            return;
        }
        
        // 3. è·å–åˆ†è¾¨ç‡
        const resolution = document.getElementById('renderResolution').value;
        let targetWidth, targetHeight;
        if (resolution === '360p') {
            targetWidth = 640; targetHeight = 360;
        } else {
            targetWidth = video.videoWidth || 1280;
            targetHeight = video.videoHeight || 720;
        }
        
        // 4. è®¡ç®—å‚æ•°
        const fps = 30;
        const sampleRate = 44100;
        const numberOfChannels = 2;
        let totalDuration = 0;
        const segmentInfos = [];
        
        scriptData.forEach((s, idx) => {
            const start = parseTime(s.time_start);
            const end = parseTime(s.time_end);
            const duration = end - start;
            segmentInfos.push({ start, end, duration, audioBuffer: audioBuffers[idx] });
            totalDuration += duration;
        });
        const totalFrames = Math.ceil(totalDuration * fps);
        
        updateRenderProgress(10, "åˆå§‹åŒ–ç¼–ç å™¨...", `å…± ${totalFrames} å¸§`);
        
        // 5. åˆ›å»º Muxer
        let muxer;
        try {
            muxer = new Mp4Muxer.Muxer({
                target: new Mp4Muxer.ArrayBufferTarget(),
                video: {
                    codec: 'avc',
                    width: targetWidth,
                    height: targetHeight
                },
                audio: {
                    codec: 'aac',
                    numberOfChannels: numberOfChannels,
                    sampleRate: sampleRate
                },
                fastStart: 'in-memory'
            });
        } catch (e) {
            showRenderProgress(false);
            alert("åˆ›å»º MP4 Muxer å¤±è´¥: " + e.message);
            return;
        }
        
        // 6. åˆ›å»º Encoders
        const videoEncoder = new VideoEncoder({
            output: (chunk, meta) => muxer.addVideoChunk(chunk, meta),
            error: (e) => console.error('VideoEncoder error:', e)
        });
        
        videoEncoder.configure({
            codec: 'avc1.42001f',
            width: targetWidth,
            height: targetHeight,
            bitrate: resolution === '360p' ? 1_000_000 : 8_000_000,
            framerate: fps
        });

        const audioEncoder = new AudioEncoder({
            output: (chunk, meta) => muxer.addAudioChunk(chunk, meta),
            error: (e) => console.error('AudioEncoder error:', e)
        });

        audioEncoder.configure({
            codec: 'mp4a.40.2',
            numberOfChannels: numberOfChannels,
            sampleRate: sampleRate,
            bitrate: 128_000
        });
        
        // 7. æ¸²æŸ“å¾ªç¯
        const renderStartTime = Date.now();
        let globalFrameIndex = 0;
        
        // ç”¨äºç»˜åˆ¶å­—å¹•çš„ Canvas
        const canvas = document.createElement('canvas');
        canvas.width = targetWidth;
        canvas.height = targetHeight;
        const ctx = canvas.getContext('2d');
        
        // è§†é¢‘é™éŸ³ï¼Œæˆ‘ä»¬è‡ªå·±å¤„ç†éŸ³é¢‘
        video.muted = true;
        
        for (let i = 0; i < segmentInfos.length; i++) {
            const seg = segmentInfos[i];
            const segFrames = Math.ceil(seg.duration * fps);
            
            // --- éŸ³é¢‘å¤„ç† ---
            // åˆ›å»ºè¯¥ç‰‡æ®µçš„éŸ³é¢‘æ•°æ®
            // ç®€å•å¤„ç†ï¼šå¦‚æœéŸ³é¢‘æ¯”è§†é¢‘çŸ­ï¼Œè¡¥é™éŸ³ï¼›å¦‚æœé•¿ï¼Œæˆªæ–­ï¼ˆæˆ–åŠ é€Ÿï¼Œè¿™é‡Œå…ˆåšç®€å•æˆªæ–­ï¼‰
            // æ›´å¥½çš„åšæ³•æ˜¯ time-stretchï¼Œä½† WebAudioAPI åœ¨ç¦»çº¿æ¨¡å¼ä¸‹åš time-stretch æ¯”è¾ƒå¤æ‚
            // è¿™é‡Œæˆ‘ä»¬é‡‡ç”¨ï¼šå¦‚æœéŸ³é¢‘é•¿ï¼Œåˆ™æˆªæ–­ï¼›å¦‚æœçŸ­ï¼Œä¿æŒåŸæ ·ï¼ˆå°¾éƒ¨è‡ªåŠ¨é™éŸ³ï¼Ÿï¼‰
            // å®é™…ä¸Šæˆ‘ä»¬éœ€è¦æŠŠ audioBuffer é‡æ–°é‡‡æ ·å¹¶ç¼–ç 
            
            // ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬æŒ‰ç‰‡æ®µç¼–ç éŸ³é¢‘
            // è®¡ç®—éœ€è¦çš„ PCM æ•°æ®é•¿åº¦
            const totalSamples = Math.ceil(seg.duration * sampleRate);
            const audioData = new Float32Array(totalSamples * numberOfChannels);
            
            // å¡«å……éŸ³é¢‘æ•°æ®
            const ab = seg.audioBuffer;
            if (ab) {
                // ç®€å•çš„é‡é‡‡æ ·/å¡«å……é€»è¾‘
                // è¿™é‡Œå‡è®¾é‡‡æ ·ç‡åŒ¹é…ï¼Œå¦‚æœä¸åŒ¹é…éœ€è¦é‡é‡‡æ ·ï¼ˆWebAudioContext decodeå·²ç»å¸®æˆ‘ä»¬é‡é‡‡æ ·åˆ°ç¯å¢ƒé‡‡æ ·ç‡äº†ï¼Œä½†æˆ‘ä»¬éœ€è¦ 44100ï¼‰
                // æš‚æ—¶å‡è®¾ audioContext.sampleRate å’Œæˆ‘ä»¬ç›®æ ‡ sampleRate ä¸€è‡´ï¼Œæˆ–è€…æ¥è¿‘
                // å®é™…ç”Ÿäº§éœ€è¦åšé‡é‡‡æ ·ï¼Œè¿™é‡Œç®€åŒ–ç›´æ¥æ‹·è´
                for (let ch = 0; ch < numberOfChannels; ch++) {
                    const chData = ab.getChannelData(Math.min(ch, ab.numberOfChannels - 1));
                    // è€ƒè™‘å€é€Ÿï¼šå¦‚æœéŸ³é¢‘å¤ªé•¿ï¼Œéœ€è¦æŒ‰æ¯”ä¾‹ä¸¢å¼ƒæ ·æœ¬ï¼›å¦‚æœçŸ­ï¼Œè¡¥0
                    // ç°åœ¨çš„é€»è¾‘æ˜¯ï¼šè§†é¢‘ç”»é¢å†³å®šæ—¶é•¿ï¼ŒéŸ³é¢‘æ’­æ”¾å¯¹åº”æ—¶é•¿
                    // è®¡ç®—æ’­æ”¾å€ç‡
                    let rate = 1.0;
                    if (ab.duration > seg.duration + 0.1) {
                         rate = ab.duration / seg.duration; // éœ€è¦åŠ é€Ÿ
                    }
                    
                    // å¡«å…… output buffer
                    for (let s = 0; s < totalSamples; s++) {
                         // æ˜ å°„åˆ°æºéŸ³é¢‘çš„æ ·æœ¬ç´¢å¼•
                         const srcIdx = Math.floor(s * rate);
                         if (srcIdx < chData.length) {
                             audioData[s * numberOfChannels + ch] = chData[srcIdx];
                         } else {
                             audioData[s * numberOfChannels + ch] = 0;
                         }
                    }
                }
            }
            
            // åˆ›å»º AudioData å¹¶ç¼–ç 
            // AudioEncoder éœ€è¦ç‰¹å®šçš„ chunk sizeï¼Œé€šå¸¸æ˜¯ 1024 çš„å€æ•°æ¡†æ¶ä¼šè‡ªåŠ¨å¤„ç†ï¼Ÿ
            // VideoEncoder/AudioEncoder éƒ½æ¥å— Data å¯¹è±¡
            // æˆ‘ä»¬å°†æ•´ä¸ªç‰‡æ®µçš„éŸ³é¢‘åˆ‡åˆ†æˆå°å—é€å…¥ Encoder
            const chunkSize = 44100; // 1ç§’ä¸€å—
            for(let offset = 0; offset < totalSamples; offset += chunkSize) {
                 const size = Math.min(chunkSize, totalSamples - offset);
                 const chunkData = new Float32Array(size * numberOfChannels);
                 // å¤åˆ¶æ•°æ®
                 for(let k=0; k<size * numberOfChannels; k++) {
                     chunkData[k] = audioData[offset * numberOfChannels + k];
                 }
                 
                 // é‡æ–°æ„å»º Planar æ•°æ®
                 const planarData = new Float32Array(size * numberOfChannels);
                 for(let s=0; s<size; s++) {
                     for(let c=0; c<numberOfChannels; c++) {
                         planarData[c * size + s] = audioData[(offset + s) * numberOfChannels + c];
                     }
                 }
                 
                 const audioFrame = new AudioData({
                    format: 'f32-planar',
                    numberOfChannels: numberOfChannels,
                    numberOfFrames: size,
                    sampleRate: sampleRate,
                    timestamp: Math.round((globalFrameIndex / fps * 1_000_000) + (offset / sampleRate * 1_000_000)),
                    data: planarData
                 });
                 
                 audioEncoder.encode(audioFrame);
                 audioFrame.close();
            }
            
            // --- è§†é¢‘å¤„ç† ---
            // é¢„åŠ è½½ seek ä¼˜åŒ–
            // ä½¿ç”¨ requestVideoFrameCallback å¹¶ä¸æ˜¯ seek çš„æ›¿ä»£ï¼Œæˆ‘ä»¬è¿˜æ˜¯éœ€è¦ seek
            // ä¼˜åŒ–ï¼šåªæœ‰å½“æ—¶é—´è·¨åº¦å¤§æ—¶æ‰ç­‰å¾… seekedï¼Œè¿ç»­å¸§é€šå¸¸å¾ˆå¿«
            
            video.currentTime = seg.start;
            // åˆå§‹ seek
             await new Promise(r => {
                const onSeeked = () => { video.removeEventListener('seeked', onSeeked); r(); };
                video.addEventListener('seeked', onSeeked);
            });
            
            for (let f = 0; f < segFrames; f++) {
                const videoTime = seg.start + (f / fps);
                // åªæœ‰å½“æ—¶é—´å˜åŠ¨è¶…è¿‡é˜ˆå€¼æ‰è®¾ç½® currentTime (æµè§ˆå™¨è‡ªå·±ä¼šæ’å€¼?)
                // ä¸ï¼Œæˆ‘ä»¬éœ€è¦ç²¾ç¡®å¸§ã€‚ä¸ºäº†é€Ÿåº¦ï¼Œæˆ‘ä»¬å¯ä»¥å®¹å¿å°‘é‡æ—¶é—´è¯¯å·®? ä¸ºäº†è´¨é‡ä¸è¡Œã€‚
                // æŠ€å·§ï¼šä¸è¦æ¯æ¬¡éƒ½ seekï¼Œè€Œæ˜¯æ’­æ”¾ videoï¼Œç„¶åæŠ“å–ï¼Ÿ
                // ä¸è¡Œï¼Œæ’­æ”¾é€Ÿåº¦ä¸å¯æ§ã€‚
                // æ–¹æ³•ï¼šè®¾ç½® currentTimeï¼Œå¦‚æœ gap å¾ˆå°ï¼Œæµè§ˆå™¨å¯èƒ½ä¸éœ€è¦è§¦å‘ seeked
                
                if (Math.abs(video.currentTime - videoTime) > 0.001) {
                    video.currentTime = videoTime;
                }
                
                // å¿«é€Ÿç­‰å¾…
                // åœ¨Chromeä¸­ï¼Œè®¾ç½®currentTimeåï¼Œæ•°æ®ä¸ä¸€å®šç«‹å³æ›´æ–°ã€‚
                // ä½†å¯¹äºæœ¬åœ°æ–‡ä»¶ï¼Œé€šå¸¸å¾ˆå¿«ã€‚
                // æˆ‘ä»¬ç”¨ä¸€ä¸ªå°æŠ€å·§ï¼šç­‰å¾… video.readyState >= 2
                while (video.readyState < 2) {
                    await new Promise(r => setTimeout(r, 10));
                }
                
                // ç»˜åˆ¶åˆ° Canvas ä»¥ä¾¿æ·»åŠ å­—å¹•
                ctx.drawImage(video, 0, 0, targetWidth, targetHeight);
                
                // ç»˜åˆ¶å­—å¹•
                ctx.font = `bold ${Math.floor(targetHeight / 15)}px "Noto Sans SC", sans-serif`;
                ctx.textAlign = 'center';
                ctx.fillStyle = 'white';
                ctx.strokeStyle = 'black';
                ctx.lineWidth = 4;
                ctx.lineJoin = 'round';
                const text = scriptData[i].voiceover;
                const textY = targetHeight - targetHeight * 0.1;
                ctx.strokeText(text, targetWidth / 2, textY);
                ctx.fillText(text, targetWidth / 2, textY);
                
                // ä» Canvas åˆ›å»º VideoFrame
                const frame = new VideoFrame(canvas, {
                    timestamp: globalFrameIndex * (1_000_000 / fps)
                });
                
                videoEncoder.encode(frame);
                frame.close(); // å¿…é¡»å…³é—­ä»¥é‡Šæ”¾æ˜¾å­˜
                
                globalFrameIndex++;
                
                // æ¯10å¸§æ›´æ–°ä¸€æ¬¡UIï¼Œé¿å…å¡é¡¿
                if (globalFrameIndex % 10 === 0) {
                     const progress = 10 + (globalFrameIndex / totalFrames) * 85;
                     const elapsed = (Date.now() - renderStartTime) / 1000;
                     const speed = globalFrameIndex / elapsed;
                     const remaining = (totalFrames - globalFrameIndex) / speed;
                     updateRenderProgress(progress, `æ¸²æŸ“å¸§ ${globalFrameIndex}/${totalFrames} (${Math.round(speed)} fps)`, `ç‰‡æ®µ ${i+1}/${scriptData.length}`, remaining);
                     // è®©å‡ºä¸»çº¿ç¨‹
                     await new Promise(r => setTimeout(r, 0));
                }
            }
        }
        
        // 9. å®Œæˆç¼–ç 
        updateRenderProgress(96, "å®Œæˆç¼–ç ...", "");
        await videoEncoder.flush();
        await audioEncoder.flush();
        videoEncoder.close();
        audioEncoder.close();
        
        // 10. ç”Ÿæˆæ–‡ä»¶
        updateRenderProgress(99, "æ‰“åŒ…æ–‡ä»¶...", "");
        muxer.finalize();
        
        const buffer = muxer.target.buffer;
        const outputBlob = new Blob([buffer], { type: 'video/mp4' });
        
        // 11. ä¸‹è½½
        const downloadUrl = URL.createObjectURL(outputBlob);
        const a = document.createElement('a');
        a.href = downloadUrl;
        a.download = 'rendered_video.mp4';
        document.body.appendChild(a);
        a.click();
        document.body.removeChild(a);
        URL.revokeObjectURL(downloadUrl);
        
        updateRenderProgress(100, "æ¸²æŸ“å®Œæˆï¼", "");
        setTimeout(() => showRenderProgress(false), 2000);
    }
    
    // ========== æ¸²æŸ“è¿›åº¦æ˜¾ç¤º ==========
    function showRenderProgress(show, label = "", detail = "") {
        const overlay = document.getElementById('renderProgressOverlay');
        overlay.style.display = show ? 'flex' : 'none';
        if (show) {
            document.getElementById('renderProgressLabel').innerText = label;
            document.getElementById('renderProgressDetail').innerText = detail;
            document.getElementById('renderProgressPercent').innerText = '0%';
            document.getElementById('renderProgressFill').style.width = '0%';
            document.getElementById('renderProgressETA').innerText = 'é¢„è®¡å‰©ä½™: --';
        }
    }
    
    function updateRenderProgress(percent, label, detail, etaSeconds) {
        document.getElementById('renderProgressPercent').innerText = Math.round(percent) + '%';
        document.getElementById('renderProgressFill').style.width = percent + '%';
        if (label) document.getElementById('renderProgressLabel').innerText = 'ğŸ¬ ' + label;
        if (detail) document.getElementById('renderProgressDetail').innerText = detail;
        if (etaSeconds !== undefined && etaSeconds > 0) {
            const mins = Math.floor(etaSeconds / 60);
            const secs = Math.floor(etaSeconds % 60);
            document.getElementById('renderProgressETA').innerText = `é¢„è®¡å‰©ä½™: ${mins}åˆ†${secs}ç§’`;
        }
        console.log(`[æ¸²æŸ“] ${Math.round(percent)}% - ${label} - ${detail}`);
    }

    // ========== FFmpeg æœåŠ¡å™¨æ¸²æŸ“ ==========
    async function startRenderExport() {
        if (!selectedVideoFile) { alert("è¯·å…ˆä¸Šä¼ è§†é¢‘æ–‡ä»¶ï¼"); return; }
        
        // ä½¿ç”¨æ™ºèƒ½è§£æå™¨
        const inputText = document.getElementById('scriptInput').value;
        const parseResult = parseScriptSmart(inputText);
        
        if (parseResult.errors.length > 0) {
            alert(showParseResult(parseResult));
            return;
        }
        
        scriptData = parseResult.scenes;
        if (parseResult.warnings.length > 0) {
            console.warn("è§£æè­¦å‘Š:", parseResult.warnings);
        }

        showLoader(true, "å‡†å¤‡æ¸²æŸ“ç´ æ...", "æ­£åœ¨æ£€æŸ¥è¯­éŸ³å®Œæ•´æ€§");

        // 2. å¼ºåˆ¶æ£€æŸ¥å¹¶ç”Ÿæˆæ‰€æœ‰éŸ³é¢‘
        try {
            for (let i = 0; i < scriptData.length; i++) {
                if (!audioCache.has(i)) {
                    loaderMsg.innerText = `æ­£åœ¨ç”Ÿæˆè¯­éŸ³ ${i+1}/${scriptData.length}`;
                    const scene = scriptData[i];
                    const blob = await fetchTTS(scene.voiceover);
                    const url = URL.createObjectURL(blob);
                    audioCache.set(i, { url, blob, text: scene.voiceover });
                    updateStatusItem(i, "âœ… æ¸²æŸ“å‡†å¤‡");
                }
            }
        } catch (e) {
            showLoader(false);
            alert("è¯­éŸ³ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ");
            return;
        }

        // 3. æ‰“åŒ…ä¸Šä¼ åˆ°åç«¯
        loaderTitle.innerText = "æ­£åœ¨æœåŠ¡å™¨æ¸²æŸ“...";
        loaderMsg.innerText = "ä¸Šä¼ ç´ æä¸­...";
        
        // Start progress polling
        let progressInterval = setInterval(async () => {
            try {
                const pRes = await fetch('/render_progress');
                if (pRes.ok) {
                    const pData = await pRes.json();
                    loaderMsg.innerText = `${pData.step}: ${pData.detail}`;
                }
            } catch {}
        }, 500);

        const formData = new FormData();
        formData.append("video_file", selectedVideoFile);
        formData.append("script_json", JSON.stringify(scriptData));
        
        // å°†æ‰€æœ‰éŸ³é¢‘æŒ‰é¡ºåºåŠ å…¥ FormData (Map éå†é¡ºåºé€šå¸¸æ˜¯æ’å…¥é¡ºåºï¼Œä½†ä¸ºäº†ä¿é™©æˆ‘ä»¬æŒ‰ç´¢å¼•éå†)
        for(let i=0; i<scriptData.length; i++) { 
            if(audioCache.has(i)) {
                formData.append("audio_files", audioCache.get(i).blob, `audio_${i}.mp3`); 
            }
        }

        try {
            const res = await fetch("/render_video", {
                method: "POST",
                body: formData
            });

            if (!res.ok) throw new Error("Server Error");

            // 4. ä¸‹è½½æ–‡ä»¶
            const blob = await res.blob();
            const url = window.URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = "rendered_video.mp4";
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            window.URL.revokeObjectURL(url);
            
            showLoader(false);
            clearInterval(progressInterval);
            alert("æ¸²æŸ“å®Œæˆï¼å·²å¼€å§‹ä¸‹è½½ã€‚");

        } catch (e) {
            showLoader(false);
            clearInterval(progressInterval);
            console.error(e);
            alert("æ¸²æŸ“å¤±è´¥ï¼Œè¯·æ£€æŸ¥åç«¯æ§åˆ¶å°æ—¥å¿— (éœ€è¦å®‰è£… FFmpeg)");
        }
    }

    // --- é¢„è§ˆæ’­æ”¾é€»è¾‘ (ç®€åŒ–ç‰ˆ) ---
    async function startProcess() {
        console.log("startProcess called");
        if (!video.src) { alert("è¯·é€‰è§†é¢‘"); return; }
        
        // ä½¿ç”¨æ™ºèƒ½è§£æå™¨
        const inputText = document.getElementById('scriptInput').value;
        const parseResult = parseScriptSmart(inputText);
        
        if (parseResult.errors.length > 0) {
            alert(showParseResult(parseResult));
            return;
        }
        
        scriptData = parseResult.scenes;
        console.log("Script parsed:", scriptData);
        
        if (parseResult.warnings.length > 0) {
            console.warn("è§£æè­¦å‘Š:", parseResult.warnings);
        }

        isRunning = true; isPaused = false; isGenerating = true;
        scriptCurrentTime = 0;  // é‡ç½®è¿›åº¦
        calculateScriptDuration();  // è®¡ç®—è„šæœ¬æ€»æ—¶é•¿
        abortController = new AbortController();
        updatePlayBtnState();
        generateQueueLoop(); // å¼€å¯åå°ç”Ÿæˆ
        playScene(0);
    }

    function togglePlayPause() {
        if (!isRunning) startProcess();
        else {
            isPaused = !isPaused;
            updatePlayBtnState();
            if(isPaused) { video.pause(); if(currentAudioObj) currentAudioObj.pause(); }
            else { video.play(); if(currentAudioObj) currentAudioObj.play(); }
        }
    }

    async function playScene(index, startOffset = 0, pauseAfterSeek = false) {
        if (!isRunning) return;
        if (index >= scriptData.length) { stopAll(); return; }

        currentSceneIndex = index;
        const scene = scriptData[index];
        const start = parseTime(scene.time_start);
        const end = parseTime(scene.time_end);
        
        subtitleEl.innerText = scene.voiceover;
        subtitleEl.style.opacity = 1;
        updateStatusItem(index, "â–¶ï¸ é¢„è§ˆä¸­");

        // è®¾ç½®è§†é¢‘ä½ç½®
        const targetVideoTime = start + startOffset;
        if (Math.abs(video.currentTime - targetVideoTime) > 0.1) video.currentTime = targetVideoTime;

        // ç­‰å¾…éŸ³é¢‘
        let audioData = audioCache.get(index);
        while (!audioData && isRunning) {
            if(!document.getElementById('loader').style.display) {
                // simple wait visual
            }
            await new Promise(r => setTimeout(r, 200));
            audioData = audioCache.get(index);
        }
        if (!isRunning) return;

        const audio = new Audio(audioData.url);
        currentAudioObj = audio;
        
        // ç®€å•åŒæ­¥é€»è¾‘
        await new Promise(r => { audio.onloadedmetadata = r; audio.load(); setTimeout(r, 500); });
        
        const vDur = end - start;
        let playbackRate = 1.0;
        if (audio.duration > vDur + 0.2) playbackRate = Math.min(audio.duration / vDur, 3.0);
        audio.playbackRate = playbackRate;

        // è®¾ç½®éŸ³é¢‘ä½ç½®
        if (startOffset > 0) {
            // æ ¹æ®å€é€Ÿè°ƒæ•´éŸ³é¢‘ä½ç½®
            // å¦‚æœéŸ³é¢‘è¢«å‹ç¼©(åŠ å¿«)ï¼ŒåŒæ ·çš„è§†é¢‘æ—¶é—´å¯¹åº”çš„éŸ³é¢‘æ—¶é—´æ›´é•¿
            // å¦‚æœéŸ³é¢‘è‡ªç„¶æ—¶é•¿ < è§†é¢‘æ—¶é•¿ï¼Œé€šå¸¸ä¸åŠ é€Ÿï¼Œæ­¤æ—¶ startOffset å¯¹åº”éŸ³é¢‘æ—¶é—´å°±æ˜¯ startOffset
            // ä½†æ˜¯è¿™é‡Œ playbackRate åªæœ‰åœ¨éŸ³é¢‘æ¯”è§†é¢‘é•¿æ—¶æ‰ > 1.0 (åŠ é€Ÿæ’­æ”¾)
            // æ‰€ä»¥éŸ³é¢‘è¿›åº¦ = è§†é¢‘è¿›åº¦ * (éŸ³é¢‘æ€»é•¿ / è§†é¢‘æ€»é•¿) ? ä¸ï¼Œæ˜¯ è§†é¢‘è¿›åº¦ * playbackRate
            // éªŒè¯: æ’­æ”¾ 1s, éŸ³é¢‘åº”è¯¥èµ° playbackRate ç§’
            audio.currentTime = startOffset * playbackRate;
        }

        if (pauseAfterSeek) {
            video.pause();
            audio.pause();
            isPaused = true;
            updatePlayBtnState();
            return; // ä»…å®šä½
        }

        video.play();
        try { await audio.play(); } catch(e) { console.error(e); }

        await new Promise(resolve => {
            let aDone = false, vDone = false;
            audio.onended = () => { aDone = true; check(); };
            const timeUp = () => {
                if(!isRunning) { video.removeEventListener('timeupdate', timeUp); resolve(); return; }
                // æ›´æ–°è„šæœ¬è¿›åº¦
                const elapsed = video.currentTime - start;
                scriptCurrentTime = segmentStartTimes[index] + Math.max(0, Math.min(elapsed, vDur));
                updateProgressDisplay();
                
                if(video.currentTime >= end) {
                    vDone = true;
                    if(!aDone) { video.pause(); video.currentTime = end; }
                    else check();
                }
            };
            video.addEventListener('timeupdate', timeUp);
            function check() { if(aDone && vDone) { video.removeEventListener('timeupdate', timeUp); resolve(); } }
        });
        
        playScene(index + 1);
    }

    // --- è¾…åŠ© ---
    function stopAll(manual) {
        isRunning = false; isGenerating = false; isPaused = false;
        if(abortController) abortController.abort();
        video.pause(); if(currentAudioObj) currentAudioObj.pause();
        updatePlayBtnState();
        if(manual) {
            audioCache.forEach(v => URL.revokeObjectURL(v.url));
            audioCache.clear();
            video.currentTime = 0;
            subtitleEl.innerText = "";
            statusList.innerHTML = "";
            scriptCurrentTime = 0;
            scriptTotalDuration = 0;
            currentTimeDisplay.textContent = '00:00 / 00:00';
            progressSlider.value = 0;
            progressSlider.style.setProperty('--progress', '0%');
        }
    }
    
    function resetProject() { stopAll(true); }
    
    // åŸºäºè„šæœ¬æ—¶é—´çš„seek
    function seek(off) { 
        if (scriptTotalDuration <= 0) return;
        const newTime = Math.max(0, Math.min(scriptCurrentTime + off, scriptTotalDuration));
        scriptCurrentTime = newTime;
        const seg = findSegmentByScriptTime(newTime);
        video.currentTime = seg.videoTime;
        updateProgressDisplay();
        
        if (isRunning && !isPaused) {
            currentSceneIndex = seg.index;
            playScene(seg.index, seg.timeInSegment);
        } else if (isRunning) {
             currentSceneIndex = seg.index;
             playScene(seg.index, seg.timeInSegment, true);
        }
    }
    
    function updatePlayBtnState() { playPauseBtn.innerText = isRunning ? (isPaused ? "â–¶ ç»§ç»­" : "â¸ æš‚åœ") : "â–¶ å¼€å§‹é¢„è§ˆ"; }
    
    // æ”¯æŒ MM:SS å’Œ HH:MM:SS æ ¼å¼
    function parseTime(s) { 
        const p = s.split(':').map(Number); 
        if (p.length === 2) return p[0]*60 + p[1];
        if (p.length === 3) return p[0]*3600 + p[1]*60 + p[2];
        return 0;
    }
    
    // TTS with retry logic
    async function fetchTTSWithRetry(text, maxRetries = 3) {
        for (let attempt = 1; attempt <= maxRetries; attempt++) {
            try {
                return await fetchTTS(text);
            } catch (e) {
                if (e.name === 'AbortError') throw e;
                console.log(`TTS attempt ${attempt} failed, retrying...`);
                if (attempt === maxRetries) throw e;
                await new Promise(r => setTimeout(r, 1000));
            }
        }
    }
    
    async function fetchTTS(text) {
        const voice = document.getElementById('voiceSelect').value;
        const rate = document.getElementById('rateSelect').value;
        const cacheKey = getCacheKey(text, voice, rate);
        
        // å…ˆæ£€æŸ¥ IndexedDB ç¼“å­˜
        const cachedBlob = await getCachedAudio(cacheKey);
        if (cachedBlob) {
            console.log('ä»ç¼“å­˜åŠ è½½éŸ³é¢‘:', text.substring(0, 20) + '...');
            return cachedBlob;
        }
        
        // æ²¡æœ‰ç¼“å­˜åˆ™è¯·æ±‚ç½‘ç»œ
        const res = await fetch('/tts', {
            method: 'POST', headers: {'Content-Type':'application/json'},
            body: JSON.stringify({text, voice, rate}),
            signal: abortController ? abortController.signal : null
        });
        if(!res.ok) throw new Error("TTS Fail");
        const blob = await res.blob();
        
        // ä¿å­˜åˆ°ç¼“å­˜
        await setCachedAudio(cacheKey, blob);
        console.log('å·²ç¼“å­˜éŸ³é¢‘:', text.substring(0, 20) + '...');
        
        return blob;
    }
    
    // Fully parallel TTS generation - all at once
    async function generateQueueLoop() {
        const promises = [];
        
        for (let idx = 0; idx < scriptData.length; idx++) {
            if (audioCache.has(idx)) continue;
            updateStatusItem(idx, "ğŸ”„ ç”Ÿæˆä¸­");
            
            const p = (async (i) => {
                try {
                    const blob = await fetchTTSWithRetry(scriptData[i].voiceover);
                    audioCache.set(i, { url: URL.createObjectURL(blob), blob, text: scriptData[i].voiceover });
                    updateStatusItem(i, "âœ… å°±ç»ª");
                } catch(e) { 
                    if(e.name !== 'AbortError') updateStatusItem(i, "âŒ å¤±è´¥"); 
                }
            })(idx);
            
            promises.push(p);
        }
        
        await Promise.all(promises);
    }

    function updateStatusItem(i, status) {
        let el = document.getElementById(`st-${i}`);
        if(!el) {
            el = document.createElement('div'); el.id=`st-${i}`; el.className='status-item';
            statusList.appendChild(el);
        }
        el.innerHTML = `<span>#${i+1}</span> <span class="${status.includes('âœ…')?'status-ready':''}">${status}</span>`;
    }

    function showLoader(show, title, msg) {
        loader.style.display = show ? 'flex' : 'none';
        if(title) loaderTitle.innerText = title;
        if(msg) loaderMsg.innerText = msg;
    }
</script>
</body>
</html>
"""

# ==========================================
# è·¯ç”±å®šä¹‰
# ==========================================

@app.get("/", response_class=HTMLResponse)
async def index():
    return HTML_CONTENT

@app.post("/tts")
async def generate_tts(
    text: str = Body(..., embed=True),
    voice: str = Body("zh-CN-XiaoxiaoNeural", embed=True),
    rate: str = Body("+0%", embed=True)
):
    communicate = edge_tts.Communicate(text, voice, rate=rate)
    audio_stream = io.BytesIO()
    async for chunk in communicate.stream():
        if chunk["type"] == "audio":
            audio_stream.write(chunk["data"])
    audio_stream.seek(0)
    return StreamingResponse(audio_stream, media_type="audio/mpeg")


@app.post("/render_video")
async def render_video_final(
    video_file: UploadFile = File(...),
    script_json: str = Form(...),
    # æ¥æ”¶æ–‡ä»¶åˆ—è¡¨
    audio_files: List[UploadFile] = File(None) 
    # æ³¨æ„ï¼šå‰ç«¯å¿…é¡»æŠŠæ‰€æœ‰ blob append åˆ° 'audio_files' è¿™ä¸ªåŒä¸€ä¸ª key ä¸‹
    # ä½†æ˜¯å‰ç«¯ JS ç°åœ¨çš„é€»è¾‘æ˜¯ audio_0, audio_1... ä¸ºäº†å…¼å®¹ä¹‹å‰çš„é€»è¾‘ï¼Œæˆ‘ä»¬éœ€è¦ä¿®æ”¹å‰ç«¯æˆ–è€…åç«¯
    # è¿™é‡Œä¿®æ”¹åç«¯å»é€‚é…å‰ç«¯çš„ key pattern æ¯”è¾ƒå›°éš¾ï¼Œæˆ‘ä»¬ä¿®æ”¹ä¸Šé¢çš„ JS ä»£ç å—ï¼Ÿ
    # ä¸ï¼Œæˆ‘ä»¬ç›´æ¥ç”¨ request.form() è¯»å–
):
    # ä¿å­˜è§†é¢‘æº
    src_video_path = os.path.join(TEMP_DIR, "source_video.mp4")
    with open(src_video_path, "wb") as f:
        shutil.copyfileobj(video_file.file, f)
    
    # è§£æè„šæœ¬
    script_data = json.loads(script_json)
    
    # ä¿å­˜éŸ³é¢‘æ–‡ä»¶åˆ° dict: index -> path
    # ç”±äº UploadFile åˆ—è¡¨é¡ºåºå¯èƒ½å’Œ append é¡ºåºä¸€è‡´ï¼Œä½†ä¸ºäº†ä¿é™©ï¼Œå‰ç«¯åº”è¯¥æŒ‰é¡ºåº append
    # æˆ–è€…å‰ç«¯å…¨éƒ¨ append åˆ° 'audio_files' åˆ—è¡¨é‡Œ
    # æˆ‘ä»¬å‡è®¾å‰ç«¯ä»£ç ä¿®æ”¹ä¸º formData.append("audio_files", blob)
    
    saved_audio_paths = {}
    
    # å¦‚æœå‰ç«¯è¿˜æ˜¯ audio_0, audio_1... æˆ‘ä»¬æ— æ³•é€šè¿‡å‚æ•°ç›´æ¥è·å–ï¼Œéœ€è¦ç”¨ request
    # ä¸ºäº†ä¿è¯ä»£ç èƒ½è·‘ï¼Œæˆ‘ä»¬åœ¨ HTML é‡Œä¿®æ”¹ JSé€»è¾‘ï¼šformData.append('audio_files', val.blob)
    # å¹¶ç¡®ä¿é¡ºåº
    
    if audio_files:
        for i, af in enumerate(audio_files):
            p = os.path.join(TEMP_DIR, f"upload_a_{i}.mp3")
            with open(p, "wb") as f:
                shutil.copyfileobj(af.file, f)
            saved_audio_paths[str(i)] = p
            
    # å¼€å§‹ FFmpeg å¤„ç†
    try:
        final_video_path = process_render(src_video_path, script_data, saved_audio_paths)
        return FileResponse(final_video_path, filename="rendered_video.mp4", media_type="video/mp4")
    except Exception as e:
        print(f"Render Error: {e}")
        return HTMLResponse(content=f"Render Failed: {e}", status_code=500)

@app.get("/render_progress")
async def get_render_progress():
    """Return current render progress from temp file"""
    progress_file = os.path.join(TEMP_DIR, "progress.txt")
    try:
        if os.path.exists(progress_file):
            with open(progress_file, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if "|" in content:
                    step, detail = content.split("|", 1)
                    return {"step": step, "detail": detail}
        return {"step": "ç­‰å¾…ä¸­", "detail": "å‡†å¤‡å¼€å§‹..."}
    except:
        return {"step": "å¤„ç†ä¸­", "detail": "..."}


# ==========================================
# CLI Mode Functions
# ==========================================

async def generate_tts_audio(text: str, voice: str, rate: str, output_path: str, max_retries: int = 3):
    """Generate TTS audio with retry logic"""
    for attempt in range(max_retries):
        try:
            communicate = edge_tts.Communicate(text, voice, rate=rate)
            await communicate.save(output_path)
            return True
        except Exception as e:
            if attempt < max_retries - 1:
                await asyncio.sleep(2)  # Wait before retry
            else:
                print(f"[TTS é”™è¯¯] ç”Ÿæˆå¤±è´¥: {str(e)[:50]}")
                raise

async def cli_generate_all_audio(script_data: list, voice: str, rate: str, output_dir: str):
    """Generate all TTS audio files with limited concurrency"""
    semaphore = asyncio.Semaphore(5)  # Limit to 5 concurrent requests
    
    async def generate_one(idx, scene):
        async with semaphore:
            output_path = os.path.join(output_dir, f"audio_{idx}.mp3")
            print(f"[TTS] ç”Ÿæˆè¯­éŸ³ {idx+1}/{len(script_data)}: {scene['voiceover'][:30]}...")
            await generate_tts_audio(scene['voiceover'], voice, rate, output_path)
    
    tasks = [generate_one(idx, scene) for idx, scene in enumerate(script_data)]
    await asyncio.gather(*tasks)
    print(f"[TTS] æ‰€æœ‰ {len(script_data)} ä¸ªè¯­éŸ³ç”Ÿæˆå®Œæˆ!")
    
    # Return paths dict
    return {str(i): os.path.join(output_dir, f"audio_{i}.mp3") for i in range(len(script_data))}

def render_from_project(project_path: str, output_path: str = None):
    """CLI: Render video from project file"""
    print(f"\n{'='*50}")
    print("æ™ºèƒ½é…éŸ³å‰ªè¾‘å™¨ - CLI æ¸²æŸ“æ¨¡å¼")
    print(f"{'='*50}\n")
    
    # Load project
    print(f"[åŠ è½½] è¯»å–å·¥ç¨‹æ–‡ä»¶: {project_path}")
    with open(project_path, "r", encoding="utf-8") as f:
        project = json.load(f)
    
    # æ™ºèƒ½è·å–è§†é¢‘è·¯å¾„
    video_path = project.get("video_path", "")
    if not video_path or not os.path.exists(video_path):
        # å°è¯•åŒåè§†é¢‘
        base_name = os.path.splitext(project_path)[0]
        auto_video = base_name + ".mp4"
        if os.path.exists(auto_video):
            video_path = auto_video
            print(f"[è‡ªåŠ¨] æ‰¾åˆ°åŒåè§†é¢‘: {video_path}")
        else:
            # å°è¯•å½“å‰ç›®å½•çš„mp4
            mp4_files = [f for f in os.listdir(os.path.dirname(project_path) or '.') if f.endswith('.mp4')]
            if mp4_files:
                video_path = os.path.join(os.path.dirname(project_path) or '.', mp4_files[0])
                print(f"[è‡ªåŠ¨] ä½¿ç”¨ç›®å½•ä¸‹ç¬¬ä¸€ä¸ªè§†é¢‘: {video_path}")
    
    # é»˜è®¤yunxiè¯­éŸ³
    voice = project.get("voice", "zh-CN-YunxiNeural")
    if not voice:
        voice = "zh-CN-YunxiNeural"
    rate = project.get("rate", "+0%")
    resolution = project.get("resolution", "native")
    
    # æ™ºèƒ½æå–è„šæœ¬
    script_data = []
    if "script_content" in project:
        for part in project["script_content"]:
            if isinstance(part, dict) and "scenes" in part:
                script_data.extend(part["scenes"])
            elif isinstance(part, dict):
                script_data.append(part)
    elif "script" in project:
        script_data = project["script"]
    elif "scenes" in project:
        script_data = project["scenes"]
    elif isinstance(project, list):
        script_data = project
    
    if not script_data:
        print("[é”™è¯¯] æ— æ³•æ‰¾åˆ°è„šæœ¬æ•°æ®")
        sys.exit(1)
    
    if not os.path.exists(video_path):
        print(f"[é”™è¯¯] è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        sys.exit(1)
    
    print(f"[è§†é¢‘] {video_path}")
    print(f"[è¯­éŸ³] {voice} @ {rate}")
    print(f"[ç‰‡æ®µ] {len(script_data)} ä¸ªåœºæ™¯")
    
    # è·å–è§†é¢‘å®é™…æ—¶é•¿å¹¶è¿‡æ»¤è¶…æ—¶ç‰‡æ®µ
    video_duration = get_duration(video_path)
    print(f"[è§†é¢‘æ—¶é•¿] {video_duration:.1f} ç§’ ({video_duration/60:.1f} åˆ†é’Ÿ)")
    
    def parse_time(t_str):
        p = list(map(float, t_str.split(':')))
        if len(p) == 2:
            return p[0]*60 + p[1]
        elif len(p) == 3:
            return p[0]*3600 + p[1]*60 + p[2]
        return 0
    
    
    # æ˜¾ç¤ºè§†é¢‘ä¿¡æ¯ï¼ˆä¸è¿‡æ»¤ï¼Œç”±åˆ‡å‰²é˜¶æ®µè‡ªåŠ¨é€‚åº”ï¼‰
    print(f"[ç‰‡æ®µ] {len(script_data)} ä¸ªåœºæ™¯ï¼ˆè¶…æ—¶ç‰‡æ®µå°†è‡ªåŠ¨é€‚åº”ï¼‰\n")
    
    # Ensure temp dir
    if os.path.exists(TEMP_DIR):
        shutil.rmtree(TEMP_DIR)
    os.makedirs(TEMP_DIR, exist_ok=True)
    
    # Generate all TTS audio
    print("[é˜¶æ®µ1] ç”Ÿæˆè¯­éŸ³...")
    audio_paths = asyncio.run(cli_generate_all_audio(script_data, voice, rate, TEMP_DIR))
    
    # Run FFmpeg render
    print("\n[é˜¶æ®µ2] FFmpeg æ¸²æŸ“...")
    print(f"[åˆ†è¾¨ç‡] {resolution}")
    final_video = process_render(video_path, script_data, audio_paths, verbose=True, resolution=resolution)
    
    # Copy to output
    if output_path is None:
        output_path = os.path.splitext(os.path.basename(video_path))[0] + "_rendered.mp4"
    
    shutil.copy(final_video, output_path)
    print(f"\n[å®Œæˆ] è¾“å‡ºæ–‡ä»¶: {os.path.abspath(output_path)}")
    
    # Cleanup
    shutil.rmtree(TEMP_DIR)
    print("[æ¸…ç†] ä¸´æ—¶æ–‡ä»¶å·²åˆ é™¤\n")

def create_sample_project(output_path: str):
    """Create a sample project file"""
    sample = {
        "video_path": "C:/path/to/your/video.mp4",
        "voice": "zh-CN-YunxiNeural",
        "rate": "+0%",
        "script": [
            {"time_start": "00:00", "time_end": "00:05", "voiceover": "è¿™æ˜¯ç¬¬ä¸€æ®µé…éŸ³æ–‡æœ¬ã€‚"},
            {"time_start": "00:05", "time_end": "00:10", "voiceover": "è¿™æ˜¯ç¬¬äºŒæ®µé…éŸ³æ–‡æœ¬ã€‚"},
            {"time_start": "00:10", "time_end": "00:15", "voiceover": "è¿™æ˜¯ç¬¬ä¸‰æ®µé…éŸ³æ–‡æœ¬ã€‚"}
        ]
    }
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(sample, f, ensure_ascii=False, indent=2)
    print(f"[å¯¼å‡º] ç¤ºä¾‹å·¥ç¨‹æ–‡ä»¶å·²åˆ›å»º: {output_path}")
    print("è¯·ç¼–è¾‘æ­¤æ–‡ä»¶ï¼Œå¡«å…¥æ­£ç¡®çš„è§†é¢‘è·¯å¾„å’Œè„šæœ¬å†…å®¹ã€‚")

def check_script(script_path: str):
    """CLI: æ£€æŸ¥è„šæœ¬æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ"""
    print(f"\n{'='*50}")
    print("æ™ºèƒ½é…éŸ³å‰ªè¾‘å™¨ - è„šæœ¬æ£€æµ‹æ¨¡å¼")
    print(f"{'='*50}\n")
    
    print(f"[æ£€æµ‹] è¯»å–æ–‡ä»¶: {script_path}")
    
    if not os.path.exists(script_path):
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    try:
        with open(script_path, "r", encoding="utf-8") as f:
            content = f.read()
    except Exception as e:
        print(f"âŒ è¯»å–å¤±è´¥: {e}")
        return
    
    # å°è¯•è§£æJSON
    try:
        raw = json.loads(content)
    except json.JSONDecodeError as e:
        print(f"âŒ JSONè§£æå¤±è´¥: {e}")
        print(f"   é”™è¯¯ä½ç½®: ç¬¬ {e.lineno} è¡Œï¼Œç¬¬ {e.colno} åˆ—")
        # æ˜¾ç¤ºé—®é¢˜é™„è¿‘
        lines = content.split('\n')
        if 0 < e.lineno <= len(lines):
            print(f"   é—®é¢˜è¡Œ: {lines[e.lineno-1][:80]}")
        return
    
    print("âœ… JSONæ ¼å¼æ­£ç¡®")
    
    # æ™ºèƒ½æå–è„šæœ¬
    script_data = []
    format_name = ""
    
    if "script_content" in raw and isinstance(raw["script_content"], list):
        for part in raw["script_content"]:
            if isinstance(part, dict) and "scenes" in part:
                script_data.extend(part["scenes"])
            elif isinstance(part, dict):
                script_data.append(part)
        format_name = "script_contentæ ¼å¼"
    elif "scenes" in raw:
        script_data = raw["scenes"]
        format_name = "scenesæ ¼å¼"
    elif "script" in raw:
        script_data = raw["script"]
        format_name = "scriptæ ¼å¼"
    elif isinstance(raw, list):
        script_data = raw
        format_name = "æ•°ç»„æ ¼å¼"
    else:
        print("âŒ æ— æ³•è¯†åˆ«è„šæœ¬æ ¼å¼")
        print("   æ”¯æŒçš„æ ¼å¼: script_content, scenes, script, æˆ–ç›´æ¥æ•°ç»„")
        return
    
    print(f"âœ… è¯†åˆ«æ ¼å¼: {format_name}")
    print(f"âœ… ç‰‡æ®µæ•°é‡: {len(script_data)}")
    
    # æ£€æŸ¥æ¯ä¸ªç‰‡æ®µ
    warnings = []
    errors = []
    valid_count = 0
    
    def parse_time(t_str):
        p = list(map(float, t_str.split(':')))
        if len(p) == 2:
            return p[0]*60 + p[1]
        elif len(p) == 3:
            return p[0]*3600 + p[1]*60 + p[2]
        return 0
    
    for idx, scene in enumerate(script_data):
        num = idx + 1
        issues = []
        
        # æ£€æŸ¥voiceover
        voiceover = scene.get("voiceover") or scene.get("text") or scene.get("content")
        if not voiceover:
            errors.append(f"ç‰‡æ®µ {num}: ç¼ºå°‘ voiceover/text/content")
            continue
        if len(voiceover.strip()) == 0:
            errors.append(f"ç‰‡æ®µ {num}: voiceover ä¸ºç©º")
            continue
        
        # æ£€æŸ¥æ—¶é—´
        time_start = scene.get("time_start") or scene.get("start") or scene.get("begin")
        time_end = scene.get("time_end") or scene.get("end")
        
        if not time_start:
            issues.append("ç¼ºå°‘ time_startï¼Œå°†è‡ªåŠ¨ç”Ÿæˆ")
        if not time_end:
            issues.append("ç¼ºå°‘ time_endï¼Œå°†è‡ªåŠ¨+5ç§’")
        
        if time_start and time_end:
            try:
                t1 = parse_time(str(time_start))
                t2 = parse_time(str(time_end))
                if t2 <= t1:
                    issues.append(f"time_end({time_end}) <= time_start({time_start})")
            except:
                issues.append("æ—¶é—´æ ¼å¼è§£æå¤±è´¥")
        
        if issues:
            warnings.append(f"ç‰‡æ®µ {num}: {'; '.join(issues)}")
        
        valid_count += 1
    
    # æ£€æŸ¥voiceè®¾ç½®
    voice = raw.get("voice", "")
    if not voice:
        print("âš ï¸  æœªæŒ‡å®šè¯­éŸ³ï¼Œå°†ä½¿ç”¨é»˜è®¤: zh-CN-YunxiNeural")
    else:
        print(f"âœ… è¯­éŸ³è®¾ç½®: {voice}")
    
    # è¾“å‡ºç»“æœ
    print(f"\n{'='*40}")
    print(f"æ£€æµ‹ç»“æœæ±‡æ€»")
    print(f"{'='*40}")
    print(f"âœ… æœ‰æ•ˆç‰‡æ®µ: {valid_count}/{len(script_data)}")
    
    if warnings:
        print(f"\nâš ï¸  è­¦å‘Š ({len(warnings)} ä¸ªï¼Œå¯è‡ªåŠ¨ä¿®å¤):")
        for w in warnings[:10]:  # æœ€å¤šæ˜¾ç¤º10ä¸ª
            print(f"   â€¢ {w}")
        if len(warnings) > 10:
            print(f"   ... è¿˜æœ‰ {len(warnings)-10} ä¸ªè­¦å‘Š")
    
    if errors:
        print(f"\nâŒ é”™è¯¯ ({len(errors)} ä¸ªï¼Œéœ€æ‰‹åŠ¨ä¿®å¤):")
        for e in errors[:10]:
            print(f"   â€¢ {e}")
        if len(errors) > 10:
            print(f"   ... è¿˜æœ‰ {len(errors)-10} ä¸ªé”™è¯¯")
    
    if not errors:
        print(f"\nâœ… è„šæœ¬å¯ç”¨ï¼å¯ä»¥è¿›è¡Œæ¸²æŸ“ã€‚")
    else:
        print(f"\nâŒ è„šæœ¬æœ‰é—®é¢˜ï¼Œè¯·ä¿®å¤åå†æ¸²æŸ“ã€‚")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="æ™ºèƒ½é…éŸ³å‰ªè¾‘å™¨ - æ”¯æŒ GUI å’Œ CLI æ¨¡å¼",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python app.py                          # å¯åŠ¨ GUI æœåŠ¡å™¨
  python app.py --render project.json    # CLI æ¸²æŸ“
  python app.py --check script.json      # æ£€æµ‹è„šæœ¬æ ¼å¼
  python app.py --export sample.json     # å¯¼å‡ºç¤ºä¾‹å·¥ç¨‹æ–‡ä»¶
  python app.py --render project.json -o output.mp4  # æŒ‡å®šè¾“å‡ºæ–‡ä»¶
        """
    )
    parser.add_argument("--render", "-r", metavar="PROJECT", help="ä»å·¥ç¨‹æ–‡ä»¶æ¸²æŸ“è§†é¢‘ (CLIæ¨¡å¼)")
    parser.add_argument("--output", "-o", metavar="FILE", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ (é…åˆ --render ä½¿ç”¨)")
    parser.add_argument("--export", "-e", metavar="FILE", help="å¯¼å‡ºç¤ºä¾‹å·¥ç¨‹æ–‡ä»¶")
    parser.add_argument("--check", "-c", metavar="SCRIPT", help="æ£€æµ‹è„šæœ¬æ–‡ä»¶æ ¼å¼")
    
    args = parser.parse_args()
    
    if args.check:
        check_script(args.check)
    elif args.render:
        render_from_project(args.render, args.output)
    elif args.export:
        create_sample_project(args.export)
    else:
        # GUI mode
        print("å¯åŠ¨æœåŠ¡å™¨: http://127.0.0.1:8000")
        uvicorn.run(app, host="127.0.0.1", port=8000)
